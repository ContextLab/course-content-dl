
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Tutorial 1: Variational Autoencoders (VAEs) &#8212; Neuromatch Academy: Deep Learning (Experimental)</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/styles/sphinx-book-theme.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/togglebutton.js"></script>
    <script src="../../../_static/clipboard.min.js"></script>
    <script src="../../../_static/copybutton.js"></script>
    <script src="../../../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script >const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../../_static/sphinx-thebe.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.1/dist/embed-amd.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <link rel="shortcut icon" href="../../../_static/nma-dl-logo-square-4xp.png"/>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="Tutorial 2: Diffusion models" href="W2D4_Tutorial2.html" />
    <link rel="prev" title="Generative Models" href="../chapter_title.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../../_static/nma-dl-logo-square-4xp.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Neuromatch Academy: Deep Learning (Experimental)</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../intro.html">
                    Introduction
                </a>
            </li>
        </ul>
        <ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../Schedule/schedule_intro.html">
   Schedule
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Schedule/daily_schedules.html">
     General schedule
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Schedule/shared_calendars.html">
     Shared calendars
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Schedule/timezone_widget.html">
     Timezone widget
    </a>
   </li>
  </ul>
 </li>
</ul>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../TechnicalHelp/tech_intro.html">
   Technical Help
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../TechnicalHelp/Jupyterbook.html">
     Using jupyterbook
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
    <label for="toctree-checkbox-3">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../TechnicalHelp/Tutorial_colab.html">
       Using Google Colab
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../TechnicalHelp/Tutorial_kaggle.html">
       Using Kaggle
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../TechnicalHelp/Discord.html">
     Using Discord
    </a>
   </li>
  </ul>
 </li>
</ul>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../TechnicalHelp/Links_Policy.html">
   Quick links and policies
  </a>
 </li>
</ul>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../prereqs/DeepLearning.html">
   Prerequisites and preparatory materials for NMA Deep Learning
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Basics Module
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W1D1_BasicsAndPytorch/chapter_title.html">
   Basics And Pytorch (W1D1)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D1_BasicsAndPytorch/student/W1D1_Tutorial1.html">
     Tutorial 1: PyTorch
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W1D2_LinearDeepLearning/chapter_title.html">
   Linear Deep Learning (W1D2)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D2_LinearDeepLearning/student/W1D2_Tutorial1.html">
     Tutorial 1: Gradient Descent and AutoGrad
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D2_LinearDeepLearning/student/W1D2_Tutorial2.html">
     Tutorial 2: Learning Hyperparameters
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D2_LinearDeepLearning/student/W1D2_Tutorial3.html">
     Tutorial 3: Deep linear neural networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D2_LinearDeepLearning/student/W1D2_BonusLecture.html">
     Bonus Lecture: Yoshua Bengio
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W1D3_MultiLayerPerceptrons/chapter_title.html">
   Multi Layer Perceptrons (W1D3)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D3_MultiLayerPerceptrons/student/W1D3_Tutorial1.html">
     Tutorial 1: Biological vs. Artificial Neural Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D3_MultiLayerPerceptrons/student/W1D3_Tutorial2.html">
     Tutorial 2: Deep MLPs
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Fine Tuning
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W1D5_Optimization/chapter_title.html">
   Optimization (W1D5)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D5_Optimization/student/W1D5_Tutorial1.html">
     Tutorial 1: Optimization techniques
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W2D1_Regularization/chapter_title.html">
   Regularization (W2D1)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D1_Regularization/student/W2D1_Tutorial1.html">
     Tutorial 1: Regularization techniques part 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D1_Regularization/student/W2D1_Tutorial2.html">
     Tutorial 2: Regularization techniques part 2
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../Module_WrapUps/FineTuning.html">
   Deep Learning: The Basics and Fine Tuning Wrap-up
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  ConvNets and Generative Models
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W2D2_ConvnetsAndDlThinking/chapter_title.html">
   Convnets And Dl Thinking (W2D2)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
  <label for="toctree-checkbox-9">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D2_ConvnetsAndDlThinking/student/W2D2_Tutorial1.html">
     Tutorial 1: Introduction to CNNs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D2_ConvnetsAndDlThinking/student/W2D2_Tutorial2.html">
     Tutorial 2: Deep Learning Thinking 1: Cost Functions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D2_ConvnetsAndDlThinking/student/W2D2_BonusLecture.html">
     Bonus Lecture: Kyunghyun Cho
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W2D3_ModernConvnets/chapter_title.html">
   Modern Convnets (W2D3)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
  <label for="toctree-checkbox-10">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D3_ModernConvnets/student/W2D3_Tutorial1.html">
     Tutorial 1: Learn how to use modern convnets
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D3_ModernConvnets/student/W2D3_Tutorial2.html">
     Bonus Tutorial: Facial recognition using modern convnets
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="../chapter_title.html">
   Generative Models (W2D4)
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
  <label for="toctree-checkbox-11">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Tutorial 1: Variational Autoencoders (VAEs)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="W2D4_Tutorial2.html">
     Tutorial 2: Diffusion models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="W2D4_Tutorial3.html">
     Tutorial 3: Image, Conditional Diffusion and Beyond
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="W2D4_BonusLecture.html">
     Bonus Lecture: Geoffrey Hinton
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Natural Language Processing
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W2D5_AttentionAndTransformers/chapter_title.html">
   Attention And Transformers (W2D5)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
  <label for="toctree-checkbox-12">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D5_AttentionAndTransformers/student/W2D5_Tutorial1.html">
     Tutorial 1: Learn how to work with Transformers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D5_AttentionAndTransformers/student/W2D5_Tutorial2.html">
     Bonus Tutorial: Understanding Pre-training, Fine-tuning and Robustness of Transformers
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W3D1_TimeSeriesAndNaturalLanguageProcessing/chapter_title.html">
   Time Series And Natural Language Processing (W3D1)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/>
  <label for="toctree-checkbox-13">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D1_TimeSeriesAndNaturalLanguageProcessing/student/W3D1_Tutorial1.html">
     Tutorial 1: Introduction to processing time series
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D1_TimeSeriesAndNaturalLanguageProcessing/student/W3D1_Tutorial2.html">
     Tutorial 2: Natural Language Processing and LLMs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D1_TimeSeriesAndNaturalLanguageProcessing/student/W3D1_Tutorial3.html">
     Bonus Tutorial: Multilingual Embeddings
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W3D2_DlThinking2/chapter_title.html">
   Dl Thinking2 (W3D2)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/>
  <label for="toctree-checkbox-14">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D2_DlThinking2/student/W3D2_Tutorial1.html">
     Tutorial 1: Deep Learning Thinking 2: Architectures and Multimodal DL thinking
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../Module_WrapUps/NaturalLanguageProcessing.html">
   Deep Learning: Convnets and NLP
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Unsupervised and Reinforcement Learning
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W3D3_UnsupervisedAndSelfSupervisedLearning/chapter_title.html">
   Unsupervised And Self Supervised Learning (W3D3)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/>
  <label for="toctree-checkbox-15">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D3_UnsupervisedAndSelfSupervisedLearning/student/W3D3_Tutorial1.html">
     Tutorial 1: Un/Self-supervised learning methods
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D3_UnsupervisedAndSelfSupervisedLearning/student/W3D3_BonusLecture.html">
     Bonus Lecture: Melanie Mitchell
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W3D4_BasicReinforcementLearning/chapter_title.html">
   Basic Reinforcement Learning (W3D4)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/>
  <label for="toctree-checkbox-16">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D4_BasicReinforcementLearning/student/W3D4_Tutorial1.html">
     Tutorial 1: Basic Reinforcement Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D4_BasicReinforcementLearning/student/W3D4_BonusLecture.html">
     Bonus Lecture: Chealsea Finn
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W3D5_ReinforcementLearningForGamesAndDlThinking3/chapter_title.html">
   Reinforcement Learning For Games And Dl Thinking3 (W3D5)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/>
  <label for="toctree-checkbox-17">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D5_ReinforcementLearningForGamesAndDlThinking3/student/W3D5_Tutorial1.html">
     Tutorial 1: Reinforcement Learning For Games
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D5_ReinforcementLearningForGamesAndDlThinking3/student/W3D5_Tutorial2.html">
     Tutorial 2: Deep Learning Thinking 3
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D5_ReinforcementLearningForGamesAndDlThinking3/student/W3D5_Tutorial3.html">
     Bonus Tutorial: Planning with Monte Carlo Tree Search
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D5_ReinforcementLearningForGamesAndDlThinking3/student/W3D5_BonusLecture.html">
     Bonus Lecture: Amita Kapoor
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Deploy Models on the Web
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../Bonus_DeployModels/chapter_title.html">
   Deploy Models (Bonus)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" type="checkbox"/>
  <label for="toctree-checkbox-18">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Bonus_DeployModels/student/Bonus_Tutorial1.html">
     Bonus Tutorial: Deploying Neural Networks on the Web
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Project Booklet
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../projects/README.html">
   Introduction to projects
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../projects/docs/project_guidance.html">
   Daily guide for projects
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../projects/modelingsteps/intro.html">
   Modeling Step-by-Step Guide
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" type="checkbox"/>
  <label for="toctree-checkbox-19">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../projects/modelingsteps/ModelingSteps_1through2_DL.html">
     Modeling Steps 1 - 2
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../projects/modelingsteps/ModelingSteps_3through4_DL.html">
     Modeling Steps 3 - 4
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../projects/modelingsteps/ModelingSteps_5through6_DL.html">
     Modeling Steps 5 - 6
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../projects/modelingsteps/ModelingSteps_7through9_DL.html">
     Modeling Steps 7 - 9
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../projects/modelingsteps/ModelingSteps_10_DL.html">
     Modeling Steps 10
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../projects/modelingsteps/TrainIllusionDataProjectDL.html">
     Example Data Project: the Train Illusion
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../projects/modelingsteps/TrainIllusionModelingProjectDL.html">
     Example Model Project: the Train Illusion
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../projects/modelingsteps/Example_Deep_Learning_Project.html">
     Example Deep Learning Project
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../projects/docs/projects_overview.html">
   Project Templates
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-20" name="toctree-checkbox-20" type="checkbox"/>
  <label for="toctree-checkbox-20">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../../projects/ComputerVision/README.html">
     Computer Vision
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-21" name="toctree-checkbox-21" type="checkbox"/>
    <label for="toctree-checkbox-21">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../../projects/ComputerVision/slides.html">
       Slides
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../../projects/ComputerVision/ideas_and_datasets.html">
       Ideas
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../../projects/ComputerVision/em_synapses.html">
       Knowledge Extraction from a Convolutional Neural Network
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../../projects/ComputerVision/spectrogram_analysis.html">
       Music classification and generation with spectrograms
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../../projects/ComputerVision/screws.html">
       Something Screwy - image recognition, detection, and classification of screws
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../../projects/ComputerVision/data_augmentation.html">
       Data Augmentation in image classification models
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../../projects/ComputerVision/transfer_learning.html">
       Transfer Learning
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../../projects/ReinforcementLearning/README.html">
     Reinforcement Learning
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-22" name="toctree-checkbox-22" type="checkbox"/>
    <label for="toctree-checkbox-22">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../../projects/ReinforcementLearning/slides.html">
       Slides
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../../projects/ReinforcementLearning/ideas_and_datasets.html">
       Ideas
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../../projects/ReinforcementLearning/robolympics.html">
       NMA Robolympics: Controlling robots using reinforcement learning
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../../projects/ReinforcementLearning/lunar_lander.html">
       Performance Analysis of DQN Algorithm on the Lunar Lander task
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../../projects/ReinforcementLearning/human_rl.html">
       Using RL to Model Cognitive Tasks
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../../projects/NaturalLanguageProcessing/README.html">
     Natural Language Processing
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-23" name="toctree-checkbox-23" type="checkbox"/>
    <label for="toctree-checkbox-23">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../../projects/NaturalLanguageProcessing/slides.html">
       Slides
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../../projects/NaturalLanguageProcessing/ideas_and_datasets.html">
       Ideas
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../../projects/NaturalLanguageProcessing/sentiment_analysis.html">
       Twitter Sentiment Analysis
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../../projects/NaturalLanguageProcessing/machine_translation.html">
       Machine Translation
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../../projects/Neuroscience/README.html">
     Neuroscience
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-24" name="toctree-checkbox-24" type="checkbox"/>
    <label for="toctree-checkbox-24">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../../projects/Neuroscience/slides.html">
       Slides
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../../projects/Neuroscience/ideas_and_datasets.html">
       Ideas
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../../projects/Neuroscience/pose_estimation.html">
       Animal Pose Estimation
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../../projects/Neuroscience/cellular_segmentation.html">
       Segmentation and Denoising
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../../projects/Neuroscience/algonauts_videos.html">
       Load algonauts videos
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../../projects/Neuroscience/blurry_vision.html">
       Vision with Lost Glasses: Modelling how the brain deals with noisy input
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../../projects/Neuroscience/finetuning_fmri.html">
       Moving beyond Labels: Finetuning CNNs on BOLD response
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../../projects/Neuroscience/neuro_seq_to_seq.html">
       Focus on what matters: inferring low-dimensional dynamics from neural recordings
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../projects/docs/datasets_and_models.html">
   Models and Data sets
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/ContextLab/course-content-dl"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/ContextLab/course-content-dl/issues/new?title=Issue%20on%20page%20%2Ftutorials/W2D4_GenerativeModels/student/W2D4_Tutorial1.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../../../_sources/tutorials/W2D4_GenerativeModels/student/W2D4_Tutorial1.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   Tutorial 1: Variational Autoencoders (VAEs)
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#tutorial-objectives">
   Tutorial Objectives
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#setup">
   Setup
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#install-dependencies">
     Install dependencies
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#please-ignore-errors-and-or-warnings-during-installation">
       Please ignore
       <em>
        errors
       </em>
       and/or
       <em>
        warnings
       </em>
       during installation.
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#install-and-import-feedback-gadget">
     Install and import feedback gadget
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#figure-settings">
     Figure settings
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#helper-functions">
     Helper functions
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#plotting-functions">
     Plotting functions
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#set-random-seed">
     Set random seed
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#set-device-gpu-or-cpu-execute-set-device">
     Set device (GPU or CPU). Execute
     <code class="docutils literal notranslate">
      <span class="pre">
       set_device()
      </span>
     </code>
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#download-wordnet-dataset">
     Download
     <code class="docutils literal notranslate">
      <span class="pre">
       wordnet
      </span>
     </code>
     dataset
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#section-1-generative-models">
   Section 1: Generative models
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#video-1-generative-modeling">
     Video 1: Generative Modeling
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#submit-your-feedback">
     Submit your feedback
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#section-1-1-generating-images-from-biggan">
     Section 1.1: Generating Images from BigGAN
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#interactive-demo-1-1-biggan-generator">
       Interactive Demo 1.1: BigGAN Generator
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#think-1-1-generated-images">
       Think! 1.1: Generated images
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#id1">
         Submit your feedback
        </a>
       </li>
      </ul>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#section-1-2-interpolating-images-with-biggan">
     Section 1.2: Interpolating Images with BigGAN
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#interactive-demo-1-2-biggan-interpolation">
       Interactive Demo 1.2: BigGAN Interpolation
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#id2">
         Submit your feedback
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#think-1-2-interpolating-samples-from-the-same-category">
       Think! 1.2: Interpolating samples from the same category
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#id3">
         Submit your feedback
        </a>
       </li>
      </ul>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#section-2-latent-variable-models">
   Section 2: Latent Variable Models
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#video-2-latent-variable-models">
     Video 2: Latent Variable Models
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id4">
     Submit your feedback
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#bonus-coding-exercise-2-ppca">
     (Bonus) Coding Exercise 2: pPCA
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id5">
       Submit your feedback
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#section-3-autoencoders">
   Section 3: Autoencoders
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#video-3-autoencoders">
     Video 3: Autoencoders
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id6">
     Submit your feedback
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#select-a-dataset">
       Select a dataset
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#section-3-1-conceptual-introduction-to-autoencoders">
     Section 3.1: Conceptual introduction to AutoEncoders
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#coding-exercise-3-1-linear-autoencoder-architecture">
       Coding Exercise 3.1: Linear AutoEncoder Architecture
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#id7">
         Submit your feedback
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#comparison-to-pca">
       Comparison to PCA
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#think-3-1-pca-vs-linear-autoenconder">
       Think! 3.1: PCA vs. Linear autoenconder
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#id8">
         Submit your feedback
        </a>
       </li>
      </ul>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#section-3-2-building-a-nonlinear-convolutional-autoencoder">
     Section 3.2: Building a nonlinear convolutional autoencoder
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#coding-exercise-3-2-fill-in-code-for-the-convautoencoder-module">
       Coding Exercise 3.2: Fill in code for the
       <code class="docutils literal notranslate">
        <span class="pre">
         ConvAutoEncoder
        </span>
       </code>
       module
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#id9">
         Submit your feedback
        </a>
       </li>
      </ul>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#section-4-variational-auto-encoders-vaes">
   Section 4: Variational Auto-Encoders (VAEs)
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#video-4-variational-autoencoders">
     Video 4: Variational Autoencoders
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id10">
     Submit your feedback
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#section-4-1-components-of-a-vae">
     Section 4.1: Components of a VAE
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#section-4-2-generating-novel-images-from-the-decoder">
     Section 4.2: Generating novel images from the decoder
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#coding-exercise-4-2-generating-images">
       Coding Exercise 4.2: Generating images
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#id11">
         Submit your feedback
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#think-4-2-autoencoders-vs-variational-autoencoders">
       Think! 4.2: AutoEncoders vs. Variational AutoEncoders
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#id12">
         Submit your feedback
        </a>
       </li>
      </ul>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#section-5-state-of-the-art-vaes-and-wrap-up">
   Section 5: State of the art VAEs and Wrap-up
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#video-5-state-of-the-art-vaes">
     Video 5: State-Of-The-Art VAEs
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id13">
     Submit your feedback
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#summary">
   Summary
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Tutorial 1: Variational Autoencoders (VAEs)</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   Tutorial 1: Variational Autoencoders (VAEs)
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#tutorial-objectives">
   Tutorial Objectives
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#setup">
   Setup
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#install-dependencies">
     Install dependencies
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#please-ignore-errors-and-or-warnings-during-installation">
       Please ignore
       <em>
        errors
       </em>
       and/or
       <em>
        warnings
       </em>
       during installation.
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#install-and-import-feedback-gadget">
     Install and import feedback gadget
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#figure-settings">
     Figure settings
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#helper-functions">
     Helper functions
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#plotting-functions">
     Plotting functions
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#set-random-seed">
     Set random seed
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#set-device-gpu-or-cpu-execute-set-device">
     Set device (GPU or CPU). Execute
     <code class="docutils literal notranslate">
      <span class="pre">
       set_device()
      </span>
     </code>
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#download-wordnet-dataset">
     Download
     <code class="docutils literal notranslate">
      <span class="pre">
       wordnet
      </span>
     </code>
     dataset
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#section-1-generative-models">
   Section 1: Generative models
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#video-1-generative-modeling">
     Video 1: Generative Modeling
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#submit-your-feedback">
     Submit your feedback
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#section-1-1-generating-images-from-biggan">
     Section 1.1: Generating Images from BigGAN
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#interactive-demo-1-1-biggan-generator">
       Interactive Demo 1.1: BigGAN Generator
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#think-1-1-generated-images">
       Think! 1.1: Generated images
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#id1">
         Submit your feedback
        </a>
       </li>
      </ul>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#section-1-2-interpolating-images-with-biggan">
     Section 1.2: Interpolating Images with BigGAN
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#interactive-demo-1-2-biggan-interpolation">
       Interactive Demo 1.2: BigGAN Interpolation
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#id2">
         Submit your feedback
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#think-1-2-interpolating-samples-from-the-same-category">
       Think! 1.2: Interpolating samples from the same category
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#id3">
         Submit your feedback
        </a>
       </li>
      </ul>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#section-2-latent-variable-models">
   Section 2: Latent Variable Models
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#video-2-latent-variable-models">
     Video 2: Latent Variable Models
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id4">
     Submit your feedback
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#bonus-coding-exercise-2-ppca">
     (Bonus) Coding Exercise 2: pPCA
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id5">
       Submit your feedback
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#section-3-autoencoders">
   Section 3: Autoencoders
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#video-3-autoencoders">
     Video 3: Autoencoders
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id6">
     Submit your feedback
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#select-a-dataset">
       Select a dataset
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#section-3-1-conceptual-introduction-to-autoencoders">
     Section 3.1: Conceptual introduction to AutoEncoders
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#coding-exercise-3-1-linear-autoencoder-architecture">
       Coding Exercise 3.1: Linear AutoEncoder Architecture
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#id7">
         Submit your feedback
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#comparison-to-pca">
       Comparison to PCA
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#think-3-1-pca-vs-linear-autoenconder">
       Think! 3.1: PCA vs. Linear autoenconder
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#id8">
         Submit your feedback
        </a>
       </li>
      </ul>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#section-3-2-building-a-nonlinear-convolutional-autoencoder">
     Section 3.2: Building a nonlinear convolutional autoencoder
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#coding-exercise-3-2-fill-in-code-for-the-convautoencoder-module">
       Coding Exercise 3.2: Fill in code for the
       <code class="docutils literal notranslate">
        <span class="pre">
         ConvAutoEncoder
        </span>
       </code>
       module
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#id9">
         Submit your feedback
        </a>
       </li>
      </ul>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#section-4-variational-auto-encoders-vaes">
   Section 4: Variational Auto-Encoders (VAEs)
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#video-4-variational-autoencoders">
     Video 4: Variational Autoencoders
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id10">
     Submit your feedback
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#section-4-1-components-of-a-vae">
     Section 4.1: Components of a VAE
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#section-4-2-generating-novel-images-from-the-decoder">
     Section 4.2: Generating novel images from the decoder
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#coding-exercise-4-2-generating-images">
       Coding Exercise 4.2: Generating images
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#id11">
         Submit your feedback
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#think-4-2-autoencoders-vs-variational-autoencoders">
       Think! 4.2: AutoEncoders vs. Variational AutoEncoders
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#id12">
         Submit your feedback
        </a>
       </li>
      </ul>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#section-5-state-of-the-art-vaes-and-wrap-up">
   Section 5: State of the art VAEs and Wrap-up
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#video-5-state-of-the-art-vaes">
     Video 5: State-Of-The-Art VAEs
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id13">
     Submit your feedback
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#summary">
   Summary
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <p><a href="https://colab.research.google.com/github/NeuromatchAcademy/course-content-dl/blob/main/tutorials/W2D4_GenerativeModels/student/W2D4_Tutorial1.ipynb" target="_blank"><img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg" /></a>  <a href="https://kaggle.com/kernels/welcome?src=https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl/main/tutorials/W2D4_GenerativeModels/student/W2D4_Tutorial1.ipynb" target="_blank"><img alt="Open in Kaggle" src="https://kaggle.com/static/images/open-in-kaggle.svg" /></a></p>
<div class="section" id="tutorial-1-variational-autoencoders-vaes">
<h1>Tutorial 1: Variational Autoencoders (VAEs)<a class="headerlink" href="#tutorial-1-variational-autoencoders-vaes" title="Permalink to this headline"></a></h1>
<p><strong>Week 2, Day 4: Generative Models</strong></p>
<p><strong>By Neuromatch Academy</strong></p>
<p><strong>Content creators:</strong> Saeed Salehi, Spiros Chavlis, Vikash Gilja</p>
<p><strong>Content reviewers:</strong> Diptodip Deb, Kelson Shilling-Scrivo</p>
<p><strong>Content editor:</strong> Charles J Edelson, Spiros Chavlis</p>
<p><strong>Production editors:</strong> Saeed Salehi, Gagana B, Spiros Chavlis</p>
<br>
<p><em>Inspired from UPenn course</em>:
<strong>Instructor:</strong> Konrad Kording, <strong>Original Content creators:</strong> Richard Lange, Arash Ash</p>
</div>
<hr class="docutils" />
<div class="section" id="tutorial-objectives">
<h1>Tutorial Objectives<a class="headerlink" href="#tutorial-objectives" title="Permalink to this headline"></a></h1>
<p>In the first tutorial of the <em>Generative Models</em> day, we are going to</p>
<ul class="simple">
<li><p>Think about unsupervised learning / Generative Models and get a birds eye view of why it is useful</p></li>
<li><p>Build intuition about latent variables</p></li>
<li><p>See the connection between AutoEncoders and PCA</p></li>
<li><p>Start thinking about neural networks as generative models by contrasting AutoEncoders and Variational AutoEncoders</p></li>
</ul>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "c338389e2c984518bba4d77051e0a8ee"}
</script></div>
</div>
</div>
<hr class="docutils" />
<div class="section" id="setup">
<h1>Setup<a class="headerlink" href="#setup" title="Permalink to this headline"></a></h1>
<div class="section" id="install-dependencies">
<h2>Install dependencies<a class="headerlink" href="#install-dependencies" title="Permalink to this headline"></a></h2>
<div class="section" id="please-ignore-errors-and-or-warnings-during-installation">
<h3>Please ignore <em>errors</em> and/or <em>warnings</em> during installation.<a class="headerlink" href="#please-ignore-errors-and-or-warnings-during-installation" title="Permalink to this headline"></a></h3>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Install dependencies</span>
<span class="c1"># @markdown #### Please ignore *errors* and/or *warnings* during installation.</span>
<span class="o">!</span>pip<span class="w"> </span>install<span class="w"> </span>pytorch-pretrained-biggan<span class="w"> </span>--quiet
<span class="o">!</span>pip<span class="w"> </span>install<span class="w"> </span>Pillow<span class="w"> </span>libsixel-python<span class="w"> </span>--quiet
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="install-and-import-feedback-gadget">
<h2>Install and import feedback gadget<a class="headerlink" href="#install-and-import-feedback-gadget" title="Permalink to this headline"></a></h2>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Install and import feedback gadget</span>

<span class="o">!</span>pip3<span class="w"> </span>install<span class="w"> </span>vibecheck<span class="w"> </span>datatops<span class="w"> </span>--quiet

<span class="kn">from</span> <span class="nn">vibecheck</span> <span class="kn">import</span> <span class="n">DatatopsContentReviewContainer</span>
<span class="k">def</span> <span class="nf">content_review</span><span class="p">(</span><span class="n">notebook_section</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">DatatopsContentReviewContainer</span><span class="p">(</span>
        <span class="s2">&quot;&quot;</span><span class="p">,</span>  <span class="c1"># No text prompt</span>
        <span class="n">notebook_section</span><span class="p">,</span>
        <span class="p">{</span>
            <span class="s2">&quot;url&quot;</span><span class="p">:</span> <span class="s2">&quot;https://pmyvdlilci.execute-api.us-east-1.amazonaws.com/klab&quot;</span><span class="p">,</span>
            <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;neuromatch_dl&quot;</span><span class="p">,</span>
            <span class="s2">&quot;user_key&quot;</span><span class="p">:</span> <span class="s2">&quot;f379rz8y&quot;</span><span class="p">,</span>
        <span class="p">},</span>
    <span class="p">)</span><span class="o">.</span><span class="n">render</span><span class="p">()</span>


<span class="n">feedback_prefix</span> <span class="o">=</span> <span class="s2">&quot;W2D4_T1&quot;</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Imports</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">random</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pylab</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>

<span class="kn">import</span> <span class="nn">torchvision</span>
<span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">datasets</span><span class="p">,</span> <span class="n">transforms</span>

<span class="kn">from</span> <span class="nn">pytorch_pretrained_biggan</span> <span class="kn">import</span> <span class="n">one_hot_from_names</span>

<span class="kn">from</span> <span class="nn">tqdm.notebook</span> <span class="kn">import</span> <span class="n">tqdm</span><span class="p">,</span> <span class="n">trange</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="figure-settings">
<h2>Figure settings<a class="headerlink" href="#figure-settings" title="Permalink to this headline"></a></h2>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Figure settings</span>
<span class="kn">import</span> <span class="nn">logging</span>
<span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="s1">&#39;matplotlib.font_manager&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">disabled</span> <span class="o">=</span> <span class="kc">True</span>

<span class="kn">import</span> <span class="nn">ipywidgets</span> <span class="k">as</span> <span class="nn">widgets</span>
<span class="kn">from</span> <span class="nn">ipywidgets</span> <span class="kn">import</span> <span class="n">FloatSlider</span><span class="p">,</span> <span class="n">IntSlider</span><span class="p">,</span> <span class="n">HBox</span><span class="p">,</span> <span class="n">Layout</span><span class="p">,</span> <span class="n">VBox</span>
<span class="kn">from</span> <span class="nn">ipywidgets</span> <span class="kn">import</span> <span class="n">interactive_output</span><span class="p">,</span> <span class="n">Dropdown</span>

<span class="o">%</span><span class="k">config</span> InlineBackend.figure_format = &#39;retina&#39;
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s2">&quot;https://raw.githubusercontent.com/NeuromatchAcademy/content-creation/main/nma.mplstyle&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="helper-functions">
<h2>Helper functions<a class="headerlink" href="#helper-functions" title="Permalink to this headline"></a></h2>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Helper functions</span>


<span class="k">def</span> <span class="nf">image_moments</span><span class="p">(</span><span class="n">image_batches</span><span class="p">,</span> <span class="n">n_batches</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">  </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">  Compute mean and covariance of all pixels</span>
<span class="sd">  from batches of images</span>

<span class="sd">  Args:</span>
<span class="sd">    Image_batches: tuple</span>
<span class="sd">      Image batches</span>
<span class="sd">    n_batches: int</span>
<span class="sd">      Number of Batch size</span>

<span class="sd">  Returns:</span>
<span class="sd">    m1: float</span>
<span class="sd">      Mean of all pixels</span>
<span class="sd">    cov: float</span>
<span class="sd">      Covariance of all pixels</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">m1</span><span class="p">,</span> <span class="n">m2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((),</span> <span class="n">device</span><span class="o">=</span><span class="n">DEVICE</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((),</span> <span class="n">device</span><span class="o">=</span><span class="n">DEVICE</span><span class="p">)</span>
  <span class="n">n</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="k">for</span> <span class="n">im</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">image_batches</span><span class="p">,</span> <span class="n">total</span><span class="o">=</span><span class="n">n_batches</span><span class="p">,</span> <span class="n">leave</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                 <span class="n">desc</span><span class="o">=</span><span class="s1">&#39;Computing pixel mean and covariance...&#39;</span><span class="p">):</span>
    <span class="n">im</span> <span class="o">=</span> <span class="n">im</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">im</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">im</span> <span class="o">=</span> <span class="n">im</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">m1</span> <span class="o">=</span> <span class="n">m1</span> <span class="o">+</span> <span class="n">im</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">m2</span> <span class="o">=</span> <span class="n">m2</span> <span class="o">+</span> <span class="p">(</span><span class="n">im</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">b</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">im</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">b</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">n</span> <span class="o">+=</span> <span class="n">b</span>
  <span class="n">m1</span><span class="p">,</span> <span class="n">m2</span> <span class="o">=</span> <span class="n">m1</span><span class="o">/</span><span class="n">n</span><span class="p">,</span> <span class="n">m2</span><span class="o">/</span><span class="n">n</span>
  <span class="n">cov</span> <span class="o">=</span> <span class="n">m2</span> <span class="o">-</span> <span class="n">m1</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">m1</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">m1</span><span class="o">.</span><span class="n">cpu</span><span class="p">(),</span> <span class="n">cov</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>


<span class="k">def</span> <span class="nf">interpolate</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">B</span><span class="p">,</span> <span class="n">num_interps</span><span class="p">):</span>
<span class="w">  </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">  Function to interpolate between images.</span>
<span class="sd">  It does this by linearly interpolating between the</span>
<span class="sd">  probability of each category you select and linearly</span>
<span class="sd">  interpolating between the latent vector values.</span>

<span class="sd">  Args:</span>
<span class="sd">    A: list</span>
<span class="sd">      List of categories</span>
<span class="sd">    B: list</span>
<span class="sd">      List of categories</span>
<span class="sd">    num_interps: int</span>
<span class="sd">      Quantity of pixel grids</span>

<span class="sd">  Returns:</span>
<span class="sd">    Interpolated np.ndarray</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">if</span> <span class="n">A</span><span class="o">.</span><span class="n">shape</span> <span class="o">!=</span> <span class="n">B</span><span class="o">.</span><span class="n">shape</span><span class="p">:</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;A and B must have the same shape to interpolate.&#39;</span><span class="p">)</span>
  <span class="n">alphas</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">num_interps</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([(</span><span class="mi">1</span><span class="o">-</span><span class="n">a</span><span class="p">)</span><span class="o">*</span><span class="n">A</span> <span class="o">+</span> <span class="n">a</span><span class="o">*</span><span class="n">B</span> <span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">alphas</span><span class="p">])</span>


<span class="k">def</span> <span class="nf">kl_q_p</span><span class="p">(</span><span class="n">zs</span><span class="p">,</span> <span class="n">phi</span><span class="p">):</span>
<span class="w">  </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">  Given [b,n,k] samples of z drawn</span>
<span class="sd">  from q, compute estimate of KL(q||p).</span>
<span class="sd">  phi must be size [b,k+1]</span>
<span class="sd">  This uses mu_p = 0 and sigma_p = 1,</span>
<span class="sd">  which simplifies the log(p(zs)) term to</span>
<span class="sd">  just -1/2*(zs**2)</span>

<span class="sd">  Args:</span>
<span class="sd">    zs: list</span>
<span class="sd">      Samples</span>
<span class="sd">    phi: list</span>
<span class="sd">      Relative entropy</span>

<span class="sd">  Returns:</span>
<span class="sd">    Size of log_q and log_p is [b,n,k].</span>
<span class="sd">    Sum along [k] but mean along [b,n]</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">b</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">k</span> <span class="o">=</span> <span class="n">zs</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
  <span class="n">mu_q</span><span class="p">,</span> <span class="n">log_sig_q</span> <span class="o">=</span> <span class="n">phi</span><span class="p">[:,:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">phi</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
  <span class="n">log_p</span> <span class="o">=</span> <span class="o">-</span><span class="mf">0.5</span><span class="o">*</span><span class="p">(</span><span class="n">zs</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
  <span class="n">log_q</span> <span class="o">=</span> <span class="o">-</span><span class="mf">0.5</span><span class="o">*</span><span class="p">(</span><span class="n">zs</span> <span class="o">-</span> <span class="n">mu_q</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">b</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="n">k</span><span class="p">))</span><span class="o">**</span><span class="mi">2</span> <span class="o">/</span> <span class="n">log_sig_q</span><span class="o">.</span><span class="n">exp</span><span class="p">()</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">b</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="o">-</span> <span class="n">log_sig_q</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">b</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
  <span class="c1"># Size of log_q and log_p is [b,n,k].</span>
  <span class="c1"># Sum along [k] but mean along [b,n]</span>
  <span class="k">return</span> <span class="p">(</span><span class="n">log_q</span> <span class="o">-</span> <span class="n">log_p</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">log_p_x</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">mu_xs</span><span class="p">,</span> <span class="n">sig_x</span><span class="p">):</span>
<span class="w">  </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">  Given [batch, ...] input x and</span>
<span class="sd">  [batch, n, ...] reconstructions, compute</span>
<span class="sd">  pixel-wise log Gaussian probability</span>
<span class="sd">  Sum over pixel dimensions, but mean over batch</span>
<span class="sd">  and samples.</span>

<span class="sd">  Args:</span>
<span class="sd">    x: np.ndarray</span>
<span class="sd">      Input Data</span>
<span class="sd">    mu_xs: np.ndarray</span>
<span class="sd">      Log of mean of samples</span>
<span class="sd">    sig_x: np.ndarray</span>
<span class="sd">      Log of standard deviation</span>

<span class="sd">  Returns:</span>
<span class="sd">    Mean over batch and samples.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">b</span><span class="p">,</span> <span class="n">n</span> <span class="o">=</span> <span class="n">mu_xs</span><span class="o">.</span><span class="n">size</span><span class="p">()[:</span><span class="mi">2</span><span class="p">]</span>
  <span class="c1"># Flatten out pixels and add a singleton</span>
  <span class="c1"># dimension [1] so that x will be</span>
  <span class="c1"># implicitly expanded when combined with mu_xs</span>
  <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
  <span class="n">squared_error</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">mu_xs</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span><span class="o">**</span><span class="mi">2</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">sig_x</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>

  <span class="c1"># Size of squared_error is [b,n,p]. log prob is</span>
  <span class="c1"># by definition sum over [p].</span>
  <span class="c1"># Expected value requires mean over [n].</span>
  <span class="c1"># Handling different size batches</span>
  <span class="c1"># requires mean over [b].</span>
  <span class="k">return</span> <span class="o">-</span><span class="p">(</span><span class="n">squared_error</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">sig_x</span><span class="p">))</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">pca_encoder_decoder</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">cov</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
<span class="w">  </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">  Compute encoder and decoder matrices</span>
<span class="sd">  for PCA dimensionality reduction</span>

<span class="sd">  Args:</span>
<span class="sd">    mu: np.ndarray</span>
<span class="sd">      Mean</span>
<span class="sd">    cov: float</span>
<span class="sd">      Covariance</span>
<span class="sd">    k: int</span>
<span class="sd">      Dimensionality</span>

<span class="sd">  Returns:</span>
<span class="sd">    Nothing</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">mu</span> <span class="o">=</span> <span class="n">mu</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
  <span class="n">u</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">v</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">svd_lowrank</span><span class="p">(</span><span class="n">cov</span><span class="p">,</span> <span class="n">q</span><span class="o">=</span><span class="n">k</span><span class="p">)</span>
  <span class="n">W_encode</span> <span class="o">=</span> <span class="n">v</span> <span class="o">/</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
  <span class="n">W_decode</span> <span class="o">=</span> <span class="n">u</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">pca_encode</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Encoder: Subtract mean image and</span>
<span class="sd">    project onto top K eigenvectors of</span>
<span class="sd">    the data covariance</span>

<span class="sd">    Args:</span>
<span class="sd">      x: torch.tensor</span>
<span class="sd">        Input data</span>

<span class="sd">    Returns:</span>
<span class="sd">      PCA Encoding</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="n">mu</span><span class="o">.</span><span class="n">numel</span><span class="p">())</span> <span class="o">-</span> <span class="n">mu</span><span class="p">)</span> <span class="o">@</span> <span class="n">W_encode</span>

  <span class="k">def</span> <span class="nf">pca_decode</span><span class="p">(</span><span class="n">h</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Decoder: un-project then add back in the mean</span>

<span class="sd">    Args:</span>
<span class="sd">      h: torch.tensor</span>
<span class="sd">        Hidden layer data</span>

<span class="sd">    Returns:</span>
<span class="sd">      PCA Decoding</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">h</span> <span class="o">@</span> <span class="n">W_decode</span><span class="o">.</span><span class="n">T</span><span class="p">)</span> <span class="o">+</span> <span class="n">mu</span>

  <span class="k">return</span> <span class="n">pca_encode</span><span class="p">,</span> <span class="n">pca_decode</span>


<span class="k">def</span> <span class="nf">cout</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">layer</span><span class="p">):</span>
<span class="w">  </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">  Unnecessarily complicated but complete way to</span>
<span class="sd">  calculate the output depth, height</span>
<span class="sd">  and width size for a Conv2D layer</span>

<span class="sd">  Args:</span>
<span class="sd">    x: tuple</span>
<span class="sd">      Input size (depth, height, width)</span>
<span class="sd">    layer: nn.Conv2d</span>
<span class="sd">      The Conv2D layer</span>

<span class="sd">  Returns:</span>
<span class="sd">    Tuple of out-depth/out-height and out-width</span>
<span class="sd">    Output shape as given in [Ref]</span>
<span class="sd">    Ref:</span>
<span class="sd">    https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">)</span>
  <span class="n">p</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">padding</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">padding</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span> <span class="k">else</span> <span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">padding</span><span class="p">,)</span>
  <span class="n">k</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">kernel_size</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">kernel_size</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span> <span class="k">else</span> <span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">kernel_size</span><span class="p">,)</span>
  <span class="n">d</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">dilation</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">dilation</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span> <span class="k">else</span> <span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">dilation</span><span class="p">,)</span>
  <span class="n">s</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">stride</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">stride</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span> <span class="k">else</span> <span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">stride</span><span class="p">,)</span>
  <span class="n">in_depth</span><span class="p">,</span> <span class="n">in_height</span><span class="p">,</span> <span class="n">in_width</span> <span class="o">=</span> <span class="n">x</span>
  <span class="n">out_depth</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">out_channels</span>
  <span class="n">out_height</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">+</span> <span class="p">(</span><span class="n">in_height</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">p</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="p">(</span><span class="n">k</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">d</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">//</span> <span class="n">s</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
  <span class="n">out_width</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">+</span> <span class="p">(</span><span class="n">in_width</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">p</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="p">(</span><span class="n">k</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">d</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">//</span> <span class="n">s</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
  <span class="k">return</span> <span class="p">(</span><span class="n">out_depth</span><span class="p">,</span> <span class="n">out_height</span><span class="p">,</span> <span class="n">out_width</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="plotting-functions">
<h2>Plotting functions<a class="headerlink" href="#plotting-functions" title="Permalink to this headline"></a></h2>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Plotting functions</span>

<span class="k">def</span> <span class="nf">plot_gen_samples_ppca</span><span class="p">(</span><span class="n">therm1</span><span class="p">,</span> <span class="n">therm2</span><span class="p">,</span> <span class="n">therm_data_sim</span><span class="p">):</span>
<span class="w">  </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">  Plotting generated samples</span>

<span class="sd">  Args:</span>
<span class="sd">    therm1: list</span>
<span class="sd">      Thermometer 1</span>
<span class="sd">    them2: list</span>
<span class="sd">      Thermometer 2</span>
<span class="sd">    therm_data_sim: list</span>
<span class="sd">      Generated (simulate, draw) `n_samples` from pPCA model</span>

<span class="sd">  Returns:</span>
<span class="sd">    Nothing</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">therm1</span><span class="p">,</span> <span class="n">therm2</span><span class="p">,</span> <span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;c&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;training data&#39;</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">therm_data_sim</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">therm_data_sim</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;m&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;&quot;generated&quot; data&#39;</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;equal&#39;</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Thermometer 1 ($^\circ$C)&#39;</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Thermometer 2 ($^\circ$C)&#39;</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>


<span class="k">def</span> <span class="nf">plot_linear_ae</span><span class="p">(</span><span class="n">lin_losses</span><span class="p">):</span>
<span class="w">  </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">  Plotting linear autoencoder</span>

<span class="sd">  Args:</span>
<span class="sd">    lin_losses: list</span>
<span class="sd">      Log of linear autoencoder MSE losses</span>

<span class="sd">  Returns:</span>
<span class="sd">    Nothing</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">lin_losses</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="o">*</span><span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">lin_losses</span><span class="p">)</span><span class="o">.</span><span class="n">median</span><span class="p">()])</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Training batch&#39;</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;MSE Loss&#39;</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>


<span class="k">def</span> <span class="nf">plot_conv_ae</span><span class="p">(</span><span class="n">lin_losses</span><span class="p">,</span> <span class="n">conv_losses</span><span class="p">):</span>
<span class="w">  </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">  Plotting convolutional autoencoder</span>

<span class="sd">  Args:</span>
<span class="sd">    lin_losses: list</span>
<span class="sd">      Log of linear autoencoder MSE losses</span>
<span class="sd">    conv_losses: list</span>
<span class="sd">      Log of convolutional model MSe losses</span>

<span class="sd">  Returns:</span>
<span class="sd">    Nothing</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">lin_losses</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">conv_losses</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s1">&#39;Lin AE&#39;</span><span class="p">,</span> <span class="s1">&#39;Conv AE&#39;</span><span class="p">])</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Training batch&#39;</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;MSE Loss&#39;</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span>
            <span class="mi">2</span><span class="o">*</span><span class="nb">max</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">conv_losses</span><span class="p">)</span><span class="o">.</span><span class="n">median</span><span class="p">(),</span>
                  <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">lin_losses</span><span class="p">)</span><span class="o">.</span><span class="n">median</span><span class="p">())])</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>


<span class="k">def</span> <span class="nf">plot_images</span><span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="n">h</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">w</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">plt_title</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">):</span>
<span class="w">  </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">  Helper function to plot images</span>

<span class="sd">  Args:</span>
<span class="sd">    images: torch.tensor</span>
<span class="sd">      Images</span>
<span class="sd">    h: int</span>
<span class="sd">      Image height</span>
<span class="sd">    w: int</span>
<span class="sd">      Image width</span>
<span class="sd">    plt_title: string</span>
<span class="sd">      Plot title</span>

<span class="sd">  Returns:</span>
<span class="sd">    Nothing</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="n">h</span><span class="o">*</span><span class="mi">2</span><span class="p">,</span> <span class="n">w</span><span class="o">*</span><span class="mi">2</span><span class="p">))</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="n">plt_title</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="mf">1.03</span><span class="p">)</span>
  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">h</span><span class="o">*</span><span class="n">w</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">plot_torch_image</span><span class="p">(</span><span class="n">images</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">plot_phi</span><span class="p">(</span><span class="n">phi</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="mi">4</span><span class="p">):</span>
<span class="w">  </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">  Contour plot of relative entropy across samples</span>

<span class="sd">  Args:</span>
<span class="sd">    phi: list</span>
<span class="sd">      Log of relative entropu changes</span>
<span class="sd">    num: int</span>
<span class="sd">      Number of interations</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">num</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">zs</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">zs</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;.&#39;</span><span class="p">)</span>
    <span class="n">th</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">6.28318</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">th</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">th</span><span class="p">)</span>
    <span class="c1"># Draw 2-sigma contours</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
        <span class="mi">2</span><span class="o">*</span><span class="n">x</span><span class="o">*</span><span class="n">phi</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">exp</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">+</span> <span class="n">phi</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span>
        <span class="mi">2</span><span class="o">*</span><span class="n">y</span><span class="o">*</span><span class="n">phi</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">exp</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">+</span> <span class="n">phi</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;equal&#39;</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">&#39;If rsample() is correct, then most but not all points should lie in the circles&#39;</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>


<span class="k">def</span> <span class="nf">plot_torch_image</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">  </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">  Helper function to plot torch image</span>

<span class="sd">  Args:</span>
<span class="sd">    image: torch.tensor</span>
<span class="sd">      Image</span>
<span class="sd">    ax: plt object</span>
<span class="sd">      If None, plt.gca()</span>

<span class="sd">  Returns:</span>
<span class="sd">    Nothing</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">ax</span> <span class="o">=</span> <span class="n">ax</span> <span class="k">if</span> <span class="n">ax</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span>
  <span class="n">c</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">w</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
  <span class="k">if</span> <span class="n">c</span><span class="o">==</span><span class="mi">1</span><span class="p">:</span>
    <span class="n">cm</span> <span class="o">=</span> <span class="s1">&#39;gray&#39;</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="n">cm</span> <span class="o">=</span> <span class="kc">None</span>

  <span class="c1"># Torch images have shape (channels, height, width)</span>
  <span class="c1"># but matplotlib expects</span>
  <span class="c1"># (height, width, channels) or just</span>
  <span class="c1"># (height,width) when grayscale</span>
  <span class="n">im_plt</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">image</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(),</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">im_plt</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cm</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">([])</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">([])</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s1">&#39;right&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s1">&#39;top&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="set-random-seed">
<h2>Set random seed<a class="headerlink" href="#set-random-seed" title="Permalink to this headline"></a></h2>
<p>Executing <code class="docutils literal notranslate"><span class="pre">set_seed(seed=seed)</span></code> you are setting the seed</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Set random seed</span>

<span class="c1"># @markdown Executing `set_seed(seed=seed)` you are setting the seed</span>

<span class="c1"># For DL its critical to set the random seed so that students can have a</span>
<span class="c1"># baseline to compare their results to expected results.</span>
<span class="c1"># Read more here: https://pytorch.org/docs/stable/notes/randomness.html</span>

<span class="c1"># Call `set_seed` function in the exercises to ensure reproducibility.</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">torch</span>

<span class="k">def</span> <span class="nf">set_seed</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">seed_torch</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">  </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">  Function that controls randomness. NumPy and random modules must be imported.</span>

<span class="sd">  Args:</span>
<span class="sd">    seed : Integer</span>
<span class="sd">      A non-negative integer that defines the random state. Default is `None`.</span>
<span class="sd">    seed_torch : Boolean</span>
<span class="sd">      If `True` sets the random seed for pytorch tensors, so pytorch module</span>
<span class="sd">      must be imported. Default is `True`.</span>

<span class="sd">  Returns:</span>
<span class="sd">    Nothing.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">if</span> <span class="n">seed</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">seed</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="mi">2</span> <span class="o">**</span> <span class="mi">32</span><span class="p">)</span>
  <span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
  <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">seed_torch</span><span class="p">:</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">manual_seed_all</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">benchmark</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">deterministic</span> <span class="o">=</span> <span class="kc">True</span>

  <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Random seed </span><span class="si">{</span><span class="n">seed</span><span class="si">}</span><span class="s1"> has been set.&#39;</span><span class="p">)</span>


<span class="c1"># In case that `DataLoader` is used</span>
<span class="k">def</span> <span class="nf">seed_worker</span><span class="p">(</span><span class="n">worker_id</span><span class="p">):</span>
<span class="w">  </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">  DataLoader will reseed workers following randomness in</span>
<span class="sd">  multi-process data loading algorithm.</span>

<span class="sd">  Args:</span>
<span class="sd">    worker_id: integer</span>
<span class="sd">      ID of subprocess to seed. 0 means that</span>
<span class="sd">      the data will be loaded in the main process</span>
<span class="sd">      Refer: https://pytorch.org/docs/stable/data.html#data-loading-randomness for more details</span>

<span class="sd">  Returns:</span>
<span class="sd">    Nothing</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">worker_seed</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">initial_seed</span><span class="p">()</span> <span class="o">%</span> <span class="mi">2</span><span class="o">**</span><span class="mi">32</span>
  <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">worker_seed</span><span class="p">)</span>
  <span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">worker_seed</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="set-device-gpu-or-cpu-execute-set-device">
<h2>Set device (GPU or CPU). Execute <code class="docutils literal notranslate"><span class="pre">set_device()</span></code><a class="headerlink" href="#set-device-gpu-or-cpu-execute-set-device" title="Permalink to this headline"></a></h2>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Set device (GPU or CPU). Execute `set_device()`</span>
<span class="c1"># especially if torch modules used.</span>

<span class="c1"># Inform the user if the notebook uses GPU or CPU.</span>

<span class="k">def</span> <span class="nf">set_device</span><span class="p">():</span>
<span class="w">  </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">  Set the device. CUDA if available, CPU otherwise</span>

<span class="sd">  Args:</span>
<span class="sd">    None</span>

<span class="sd">  Returns:</span>
<span class="sd">    Nothing</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">device</span> <span class="o">=</span> <span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span>
  <span class="k">if</span> <span class="n">device</span> <span class="o">!=</span> <span class="s2">&quot;cuda&quot;</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;WARNING: For this notebook to perform best, &quot;</span>
        <span class="s2">&quot;if possible, in the menu under `Runtime` -&gt; &quot;</span>
        <span class="s2">&quot;`Change runtime type.`  select `GPU` &quot;</span><span class="p">)</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;GPU is enabled in this notebook.&quot;</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">device</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">SEED</span> <span class="o">=</span> <span class="mi">2021</span>
<span class="n">set_seed</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>
<span class="n">DEVICE</span> <span class="o">=</span> <span class="n">set_device</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Random seed 2021 has been set.
WARNING: For this notebook to perform best, if possible, in the menu under `Runtime` -&gt; `Change runtime type.`  select `GPU` 
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="download-wordnet-dataset">
<h2>Download <code class="docutils literal notranslate"><span class="pre">wordnet</span></code> dataset<a class="headerlink" href="#download-wordnet-dataset" title="Permalink to this headline"></a></h2>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Download `wordnet` dataset</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">NLTK Download:</span>

<span class="sd">import nltk</span>
<span class="sd">nltk.download(&#39;wordnet&#39;)</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">import</span> <span class="nn">os</span><span class="o">,</span> <span class="nn">requests</span><span class="o">,</span> <span class="nn">zipfile</span>

<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;NLTK_DATA&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;nltk_data/&#39;</span>

<span class="n">fnames</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;wordnet.zip&#39;</span><span class="p">,</span> <span class="s1">&#39;omw-1.4.zip&#39;</span><span class="p">]</span>
<span class="n">urls</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;https://osf.io/ekjxy/download&#39;</span><span class="p">,</span> <span class="s1">&#39;https://osf.io/kuwep/download&#39;</span><span class="p">]</span>

<span class="k">for</span> <span class="n">fname</span><span class="p">,</span> <span class="n">url</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">fnames</span><span class="p">,</span> <span class="n">urls</span><span class="p">):</span>
  <span class="n">r</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">allow_redirects</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

  <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">fname</span><span class="p">,</span> <span class="s1">&#39;wb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">fd</span><span class="p">:</span>
    <span class="n">fd</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">r</span><span class="o">.</span><span class="n">content</span><span class="p">)</span>

  <span class="k">with</span> <span class="n">zipfile</span><span class="o">.</span><span class="n">ZipFile</span><span class="p">(</span><span class="n">fname</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">zip_ref</span><span class="p">:</span>
    <span class="n">zip_ref</span><span class="o">.</span><span class="n">extractall</span><span class="p">(</span><span class="s1">&#39;nltk_data/corpora&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<hr class="docutils" />
<div class="section" id="section-1-generative-models">
<h1>Section 1: Generative models<a class="headerlink" href="#section-1-generative-models" title="Permalink to this headline"></a></h1>
<p><em>Time estimate: ~15mins</em></p>
<p><strong>Please</strong> run the cell after the video to download BigGAN (a generative model) and a few standard image datasets while the video plays.</p>
<div class="section" id="video-1-generative-modeling">
<h2>Video 1: Generative Modeling<a class="headerlink" href="#video-1-generative-modeling" title="Permalink to this headline"></a></h2>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "02253eb166f44959a6b692e47c8354d0"}
</script></div>
</div>
</div>
<div class="section" id="submit-your-feedback">
<h2>Submit your feedback<a class="headerlink" href="#submit-your-feedback" title="Permalink to this headline"></a></h2>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Submit your feedback</span>
<span class="n">content_review</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">feedback_prefix</span><span class="si">}</span><span class="s2">_Generative_Modeling_Video&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "39bb49822db74d6bb12ffe6d11a816a1"}
</script></div>
</div>
<p>Download BigGAN (a generative model) and a few standard image datasets</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @markdown Download BigGAN (a generative model) and a few standard image datasets</span>

<span class="c1">## Initially was downloaded directly</span>
<span class="c1"># biggan_model = BigGAN.from_pretrained(&#39;biggan-deep-256&#39;)</span>

<span class="n">url</span> <span class="o">=</span> <span class="s2">&quot;https://osf.io/3yvhw/download&quot;</span>
<span class="n">fname</span> <span class="o">=</span> <span class="s2">&quot;biggan_deep_256&quot;</span>
<span class="n">r</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">allow_redirects</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">fname</span><span class="p">,</span> <span class="s1">&#39;wb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">fd</span><span class="p">:</span>
  <span class="n">fd</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">r</span><span class="o">.</span><span class="n">content</span><span class="p">)</span>

<span class="n">biggan_model</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">fname</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="section-1-1-generating-images-from-biggan">
<h2>Section 1.1: Generating Images from BigGAN<a class="headerlink" href="#section-1-1-generating-images-from-biggan" title="Permalink to this headline"></a></h2>
<p>To demonstrate the power of generative models, we are giving you a sneak peek of a fully trained generative model called BigGAN. Youll see it again (with more background under your belt) later today. For now, lets just focus on BigGAN as a generative model. Specifically, BigGAN is a class conditional generative model for <span class="math notranslate nohighlight">\(128 \times 128\)</span> images. The classes are based on categorical labels that describe the images and images are generated based upon a vector (<span class="math notranslate nohighlight">\(z\)</span> from the video lecture) and the probability that the image comes from a specific discrete category.</p>
<p>For now, dont worry about the specifics of the model other than the fact that it generates images based on the vector and the category label.</p>
<div class="section" id="interactive-demo-1-1-biggan-generator">
<h3>Interactive Demo 1.1: BigGAN Generator<a class="headerlink" href="#interactive-demo-1-1-biggan-generator" title="Permalink to this headline"></a></h3>
<p>To explore the space of generated images, weve provided you with a widget that allows you to select a category label, generate four different z vectors, and view generated images based on those z vectors. The z vector is a 128-D, which may seem high dimensional, but is much lower-dimensional than a <span class="math notranslate nohighlight">\(128 \times 128\)</span> image!</p>
<p>There is one additional slider option below: the z vector is being generated from a truncated normal distribution, where you are choosing the truncation value. Essentially, you are controlling the magnitude of the vector. <strong>You dont need to worry about the details for now though, were just making a conceptual point here and you dont need to know the ins and outs of truncation values or z vectors.</strong></p>
<p>Just know that each time you change the category or truncation value slider, 4 different z vectors are generated, resulting in 4 different images</p>
<p>BigGAN Image Generator (the updates may take a few seconds, please be patient)</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @markdown BigGAN Image Generator (the updates may take a few seconds, please be patient)</span>

<span class="c1"># category = &#39;German shepherd&#39; # @param [&#39;tench&#39;, &#39;magpie&#39;, &#39;jellyfish&#39;, &#39;German shepherd&#39;, &#39;bee&#39;, &#39;acoustic guitar&#39;, &#39;coffee mug&#39;, &#39;minibus&#39;, &#39;monitor&#39;]</span>
<span class="c1"># z_magnitude = .1 # @param {type:&quot;slider&quot;, min:0, max:1, step:.1}</span>


<span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">truncnorm</span>
<span class="k">def</span> <span class="nf">truncated_noise_sample</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">dim_z</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot; Create a truncated noise vector.</span>
<span class="sd">        Params:</span>
<span class="sd">            batch_size: batch size.</span>
<span class="sd">            dim_z: dimension of z</span>
<span class="sd">            truncation: truncation value to use</span>
<span class="sd">            seed: seed for the random generator</span>
<span class="sd">        Output:</span>
<span class="sd">            array of shape (batch_size, dim_z)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">state</span> <span class="o">=</span> <span class="kc">None</span> <span class="k">if</span> <span class="n">seed</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">values</span> <span class="o">=</span> <span class="n">truncnorm</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">dim_z</span><span class="p">),</span> <span class="n">random_state</span><span class="o">=</span><span class="n">state</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">truncation</span> <span class="o">*</span> <span class="n">values</span>


<span class="k">def</span> <span class="nf">sample_from_biggan</span><span class="p">(</span><span class="n">category</span><span class="p">,</span> <span class="n">z_magnitude</span><span class="p">):</span>
<span class="w">  </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">  Sample from BigGAN Image Generator</span>

<span class="sd">  Args:</span>
<span class="sd">    category: string</span>
<span class="sd">      Category</span>
<span class="sd">    z_magnitude: int</span>
<span class="sd">      Magnitude of variation vector</span>

<span class="sd">  Returns:</span>
<span class="sd">    Nothing</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="n">truncation</span> <span class="o">=</span> <span class="n">z_magnitude</span>
  <span class="n">z</span> <span class="o">=</span> <span class="n">truncated_noise_sample</span><span class="p">(</span><span class="n">truncation</span><span class="o">=</span><span class="n">truncation</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
  <span class="n">y</span> <span class="o">=</span> <span class="n">one_hot_from_names</span><span class="p">(</span><span class="n">category</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>

  <span class="n">z</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
  <span class="n">z</span> <span class="o">=</span> <span class="n">z</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
  <span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

  <span class="c1"># Move to GPU</span>
  <span class="n">z</span> <span class="o">=</span> <span class="n">z</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">set_device</span><span class="p">())</span>
  <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">set_device</span><span class="p">())</span>
  <span class="n">biggan_model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">set_device</span><span class="p">())</span>


  <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">biggan_model</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">truncation</span><span class="p">)</span>

  <span class="c1"># Back to CPU</span>
  <span class="n">output</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span>

  <span class="c1"># The output layer of BigGAN has a tanh layer,</span>
  <span class="c1"># resulting the range of [-1, 1] for the output image</span>
  <span class="c1"># Therefore, we normalize the images properly to [0, 1]</span>
  <span class="c1"># range.</span>
  <span class="c1"># Clipping is only in case of numerical instability</span>
  <span class="c1"># problems</span>

  <span class="n">output</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">clip</span><span class="p">(((</span><span class="n">output</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="mf">2.0</span><span class="p">),</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

  <span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
  <span class="n">axes</span> <span class="o">=</span> <span class="n">axes</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
  <span class="k">for</span> <span class="n">im</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">):</span>

    <span class="n">axes</span><span class="p">[</span><span class="n">im</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="n">im</span><span class="p">]</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span><span class="o">.</span><span class="n">moveaxis</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">im</span><span class="p">]</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>

<span class="n">z_slider</span> <span class="o">=</span> <span class="n">FloatSlider</span><span class="p">(</span><span class="nb">min</span><span class="o">=</span><span class="mf">.1</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mf">.1</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
                     <span class="n">continuous_update</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                     <span class="n">description</span><span class="o">=</span><span class="s1">&#39;Truncation Value&#39;</span><span class="p">,</span>
                     <span class="n">style</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;description_width&#39;</span><span class="p">:</span> <span class="s1">&#39;100px&#39;</span><span class="p">},</span>
                     <span class="n">layout</span><span class="o">=</span><span class="n">Layout</span><span class="p">(</span><span class="n">width</span><span class="o">=</span><span class="s1">&#39;440px&#39;</span><span class="p">))</span>

<span class="n">category_dropdown</span> <span class="o">=</span> <span class="n">Dropdown</span><span class="p">(</span>
    <span class="n">options</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;tench&#39;</span><span class="p">,</span> <span class="s1">&#39;magpie&#39;</span><span class="p">,</span> <span class="s1">&#39;jellyfish&#39;</span><span class="p">,</span> <span class="s1">&#39;German shepherd&#39;</span><span class="p">,</span> <span class="s1">&#39;bee&#39;</span><span class="p">,</span>
             <span class="s1">&#39;acoustic guitar&#39;</span><span class="p">,</span> <span class="s1">&#39;coffee mug&#39;</span><span class="p">,</span> <span class="s1">&#39;minibus&#39;</span><span class="p">,</span> <span class="s1">&#39;monitor&#39;</span><span class="p">],</span>
             <span class="n">value</span><span class="o">=</span><span class="s2">&quot;German shepherd&quot;</span><span class="p">,</span>
             <span class="n">description</span><span class="o">=</span><span class="s2">&quot;Category: &quot;</span><span class="p">)</span>

<span class="n">widgets_ui</span> <span class="o">=</span> <span class="n">VBox</span><span class="p">([</span><span class="n">category_dropdown</span><span class="p">,</span> <span class="n">z_slider</span><span class="p">])</span>

<span class="n">widgets_out</span> <span class="o">=</span> <span class="n">interactive_output</span><span class="p">(</span><span class="n">sample_from_biggan</span><span class="p">,</span>
                                 <span class="p">{</span>
                                  <span class="s1">&#39;z_magnitude&#39;</span><span class="p">:</span> <span class="n">z_slider</span><span class="p">,</span>
                                  <span class="s1">&#39;category&#39;</span><span class="p">:</span> <span class="n">category_dropdown</span>
                                  <span class="p">}</span>
                                 <span class="p">)</span>

<span class="n">display</span><span class="p">(</span><span class="n">widgets_ui</span><span class="p">,</span> <span class="n">widgets_out</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "5f3adfc1351244b8b004b94c725f2b4b"}
</script><script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "8186cccec7a9492d95a9a779fd1c15c2"}
</script></div>
</div>
</div>
<div class="section" id="think-1-1-generated-images">
<h3>Think! 1.1: Generated images<a class="headerlink" href="#think-1-1-generated-images" title="Permalink to this headline"></a></h3>
<p>How do the generated images look? Do they look realistic or obviously fake to you?</p>
<p>As you increase the truncation value, what do you note about the generated images and the relationship between them?</p>
<p><a class="reference external" href="https://github.com/NeuromatchAcademy/course-content-dl/tree/main/tutorials/W2D4_GenerativeModels/solutions/W2D4_Tutorial1_Solution_f833b825.py"><em>Click for solution</em></a></p>
<div class="section" id="id1">
<h4>Submit your feedback<a class="headerlink" href="#id1" title="Permalink to this headline"></a></h4>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Submit your feedback</span>
<span class="n">content_review</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">feedback_prefix</span><span class="si">}</span><span class="s2">_Generated_Images_Discussion&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "4bb1f1e306c14654b4f8fb4faa608420"}
</script></div>
</div>
</div>
</div>
</div>
<div class="section" id="section-1-2-interpolating-images-with-biggan">
<h2>Section 1.2: Interpolating Images with BigGAN<a class="headerlink" href="#section-1-2-interpolating-images-with-biggan" title="Permalink to this headline"></a></h2>
<p>This next widget allows you to interpolate between two generated images. It does this by linearly interpolating between the probability of each category you select and linearly interpolating between the latent vector values.</p>
<div class="section" id="interactive-demo-1-2-biggan-interpolation">
<h3>Interactive Demo 1.2: BigGAN Interpolation<a class="headerlink" href="#interactive-demo-1-2-biggan-interpolation" title="Permalink to this headline"></a></h3>
<p>BigGAN Interpolation Widget (the updates may take a few seconds)</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @markdown BigGAN Interpolation Widget (the updates may take a few seconds)</span>

<span class="k">def</span> <span class="nf">interpolate_biggan</span><span class="p">(</span><span class="n">category_A</span><span class="p">,</span>
                       <span class="n">category_B</span><span class="p">):</span>
<span class="w">  </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">  Interpolation function with BigGan</span>

<span class="sd">  Args:</span>
<span class="sd">    category_A: string</span>
<span class="sd">      Category specification</span>
<span class="sd">    category_B: string</span>
<span class="sd">      Category specification</span>

<span class="sd">  Returns:</span>
<span class="sd">    Nothing</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">num_interps</span> <span class="o">=</span> <span class="mi">16</span>

  <span class="c1"># category_A = &#39;jellyfish&#39; #@param [&#39;tench&#39;, &#39;magpie&#39;, &#39;jellyfish&#39;, &#39;German shepherd&#39;, &#39;bee&#39;, &#39;acoustic guitar&#39;, &#39;coffee mug&#39;, &#39;minibus&#39;, &#39;monitor&#39;]</span>
  <span class="c1"># z_magnitude_A = 0 #@param {type:&quot;slider&quot;, min:-10, max:10, step:1}</span>

  <span class="c1"># category_B = &#39;German shepherd&#39; #@param [&#39;tench&#39;, &#39;magpie&#39;, &#39;jellyfish&#39;, &#39;German shepherd&#39;, &#39;bee&#39;, &#39;acoustic guitar&#39;, &#39;coffee mug&#39;, &#39;minibus&#39;, &#39;monitor&#39;]</span>
  <span class="c1"># z_magnitude_B = 0 #@param {type:&quot;slider&quot;, min:-10, max:10, step:1}</span>


  <span class="k">def</span> <span class="nf">interpolate_and_shape</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">B</span><span class="p">,</span> <span class="n">num_interps</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Function to interpolate and shape images.</span>
<span class="sd">    It does this by linearly interpolating between the</span>
<span class="sd">    probability of each category you select and linearly</span>
<span class="sd">    interpolating between the latent vector values.</span>

<span class="sd">    Args:</span>
<span class="sd">      A: list</span>
<span class="sd">        List of categories</span>
<span class="sd">      B: list</span>
<span class="sd">        List of categories</span>
<span class="sd">      num_interps: int</span>
<span class="sd">        Quantity of pixel grids</span>

<span class="sd">    Returns:</span>
<span class="sd">      Interpolated np.ndarray</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">interps</span> <span class="o">=</span> <span class="n">interpolate</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">B</span><span class="p">,</span> <span class="n">num_interps</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">interps</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="o">*</span><span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">interps</span><span class="o">.</span><span class="n">shape</span><span class="p">)))</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">num_interps</span><span class="p">,</span> <span class="o">*</span><span class="n">interps</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">:]))</span>

  <span class="c1"># unit_vector = np.ones((1, 128))/np.sqrt(128)</span>
  <span class="c1"># z_A = z_magnitude_A * unit_vector</span>
  <span class="c1"># z_B = z_magnitude_B * unit_vector</span>
  <span class="n">truncation</span> <span class="o">=</span> <span class="mf">.4</span>
  <span class="n">z_A</span> <span class="o">=</span> <span class="n">truncated_noise_sample</span><span class="p">(</span><span class="n">truncation</span><span class="o">=</span><span class="n">truncation</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
  <span class="n">z_B</span> <span class="o">=</span> <span class="n">truncated_noise_sample</span><span class="p">(</span><span class="n">truncation</span><span class="o">=</span><span class="n">truncation</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
  <span class="n">y_A</span> <span class="o">=</span> <span class="n">one_hot_from_names</span><span class="p">(</span><span class="n">category_A</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
  <span class="n">y_B</span> <span class="o">=</span> <span class="n">one_hot_from_names</span><span class="p">(</span><span class="n">category_B</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

  <span class="n">z_interp</span> <span class="o">=</span> <span class="n">interpolate_and_shape</span><span class="p">(</span><span class="n">z_A</span><span class="p">,</span> <span class="n">z_B</span><span class="p">,</span> <span class="n">num_interps</span><span class="p">)</span>
  <span class="n">y_interp</span> <span class="o">=</span> <span class="n">interpolate_and_shape</span><span class="p">(</span><span class="n">y_A</span><span class="p">,</span> <span class="n">y_B</span><span class="p">,</span> <span class="n">num_interps</span><span class="p">)</span>

  <span class="c1"># Convert to tensor</span>
  <span class="n">z_interp</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">z_interp</span><span class="p">)</span>
  <span class="n">z_interp</span> <span class="o">=</span> <span class="n">z_interp</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
  <span class="n">y_interp</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">y_interp</span><span class="p">)</span>

  <span class="c1"># Move to GPU</span>
  <span class="n">z_interp</span> <span class="o">=</span> <span class="n">z_interp</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
  <span class="n">y_interp</span> <span class="o">=</span> <span class="n">y_interp</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
  <span class="n">biggan_model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>

  <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">biggan_model</span><span class="p">(</span><span class="n">z_interp</span><span class="p">,</span> <span class="n">y_interp</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

  <span class="c1"># Back to CPU</span>
  <span class="n">output</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span>

  <span class="c1"># The output layer of BigGAN has a tanh layer,</span>
  <span class="c1"># resulting the range of [-1, 1] for the output image</span>
  <span class="c1"># Therefore, we normalize the images properly to</span>
  <span class="c1"># [0, 1] range.</span>
  <span class="c1"># Clipping is only in case of numerical instability</span>
  <span class="c1"># problems</span>

  <span class="n">output</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">clip</span><span class="p">(((</span><span class="n">output</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="mf">2.0</span><span class="p">),</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
  <span class="n">output</span> <span class="o">=</span> <span class="n">output</span>

  <span class="c1"># Make grid and show generated samples</span>
  <span class="n">output_grid</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">make_grid</span><span class="p">(</span><span class="n">output</span><span class="p">,</span>
                                            <span class="n">nrow</span><span class="o">=</span><span class="nb">min</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="n">output</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span>
                                            <span class="n">padding</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">);</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">output_grid</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>


<span class="c1"># z_A_slider = IntSlider(min=-10, max=10, step=1, value=0,</span>
<span class="c1">#                        continuous_update=False, description=&#39;Z Magnitude A&#39;,</span>
<span class="c1">#                        layout=Layout(width=&#39;440px&#39;),</span>
<span class="c1">#                        style={&#39;description_width&#39;: &#39;initial&#39;})</span>

<span class="c1"># z_B_slider = IntSlider(min=-10, max=10, step=1, value=0,</span>
<span class="c1">#                        continuous_update=False, description=&#39;Z Magntude B&#39;,</span>
<span class="c1">#                        layout=Layout(width=&#39;440px&#39;),</span>
<span class="c1">#                        style={&#39;description_width&#39;: &#39;initial&#39;})</span>

<span class="n">category_A_dropdown</span> <span class="o">=</span> <span class="n">Dropdown</span><span class="p">(</span>
    <span class="n">options</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;tench&#39;</span><span class="p">,</span> <span class="s1">&#39;magpie&#39;</span><span class="p">,</span> <span class="s1">&#39;jellyfish&#39;</span><span class="p">,</span> <span class="s1">&#39;German shepherd&#39;</span><span class="p">,</span> <span class="s1">&#39;bee&#39;</span><span class="p">,</span>
             <span class="s1">&#39;acoustic guitar&#39;</span><span class="p">,</span> <span class="s1">&#39;coffee mug&#39;</span><span class="p">,</span> <span class="s1">&#39;minibus&#39;</span><span class="p">,</span> <span class="s1">&#39;monitor&#39;</span><span class="p">],</span>
             <span class="n">value</span><span class="o">=</span><span class="s2">&quot;German shepherd&quot;</span><span class="p">,</span>
             <span class="n">description</span><span class="o">=</span><span class="s2">&quot;Category A: &quot;</span><span class="p">)</span>

<span class="n">category_B_dropdown</span> <span class="o">=</span> <span class="n">Dropdown</span><span class="p">(</span>
    <span class="n">options</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;tench&#39;</span><span class="p">,</span> <span class="s1">&#39;magpie&#39;</span><span class="p">,</span> <span class="s1">&#39;jellyfish&#39;</span><span class="p">,</span> <span class="s1">&#39;German shepherd&#39;</span><span class="p">,</span> <span class="s1">&#39;bee&#39;</span><span class="p">,</span>
             <span class="s1">&#39;acoustic guitar&#39;</span><span class="p">,</span> <span class="s1">&#39;coffee mug&#39;</span><span class="p">,</span> <span class="s1">&#39;minibus&#39;</span><span class="p">,</span> <span class="s1">&#39;monitor&#39;</span><span class="p">],</span>
             <span class="n">value</span><span class="o">=</span><span class="s2">&quot;jellyfish&quot;</span><span class="p">,</span>
             <span class="n">description</span><span class="o">=</span><span class="s2">&quot;Category B: &quot;</span><span class="p">)</span>



<span class="n">widgets_ui</span> <span class="o">=</span> <span class="n">VBox</span><span class="p">([</span><span class="n">HBox</span><span class="p">([</span><span class="n">category_A_dropdown</span><span class="p">]),</span>
                   <span class="n">HBox</span><span class="p">([</span><span class="n">category_B_dropdown</span><span class="p">])])</span>

<span class="n">widgets_out</span> <span class="o">=</span> <span class="n">interactive_output</span><span class="p">(</span><span class="n">interpolate_biggan</span><span class="p">,</span>
                                 <span class="p">{</span><span class="s1">&#39;category_A&#39;</span><span class="p">:</span> <span class="n">category_A_dropdown</span><span class="p">,</span>
                                  <span class="c1"># &#39;z_magnitude_A&#39;: z_A_slider,</span>
                                  <span class="s1">&#39;category_B&#39;</span><span class="p">:</span> <span class="n">category_B_dropdown</span><span class="p">})</span>
                                  <span class="c1"># &#39;z_magnitude_B&#39;: z_B_slider})</span>

<span class="n">display</span><span class="p">(</span><span class="n">widgets_ui</span><span class="p">,</span> <span class="n">widgets_out</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "da7c4a6887f1419eaa92ecd54d34e20f"}
</script><script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "0a4e1b99907142e4a525e2cc2e4645f3"}
</script></div>
</div>
<div class="section" id="id2">
<h4>Submit your feedback<a class="headerlink" href="#id2" title="Permalink to this headline"></a></h4>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Submit your feedback</span>
<span class="n">content_review</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">feedback_prefix</span><span class="si">}</span><span class="s2">_BigGAN_Interpolation_Interactive_Demo&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "cbb17fe4e69d4f9695d465cd55477348"}
</script></div>
</div>
</div>
</div>
<div class="section" id="think-1-2-interpolating-samples-from-the-same-category">
<h3>Think! 1.2: Interpolating samples from the same category<a class="headerlink" href="#think-1-2-interpolating-samples-from-the-same-category" title="Permalink to this headline"></a></h3>
<p>Try interpolating between samples from the same category, samples from similar categories, and samples from very different categories. Do you notice any trends? What does this suggest about the representations of images in the latent space?</p>
<p><a class="reference external" href="https://github.com/NeuromatchAcademy/course-content-dl/tree/main/tutorials/W2D4_GenerativeModels/solutions/W2D4_Tutorial1_Solution_09759a98.py"><em>Click for solution</em></a></p>
<div class="section" id="id3">
<h4>Submit your feedback<a class="headerlink" href="#id3" title="Permalink to this headline"></a></h4>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Submit your feedback</span>
<span class="n">content_review</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">feedback_prefix</span><span class="si">}</span><span class="s2">_Samples_from_the_same_category_Discussion&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "4b4448d386d74ec2861abe3056f85eb4"}
</script></div>
</div>
</div>
</div>
</div>
</div>
<hr class="docutils" />
<div class="section" id="section-2-latent-variable-models">
<h1>Section 2: Latent Variable Models<a class="headerlink" href="#section-2-latent-variable-models" title="Permalink to this headline"></a></h1>
<p><em>Time estimate: ~15mins</em> excluding the Bonus</p>
<div class="section" id="video-2-latent-variable-models">
<h2>Video 2: Latent Variable Models<a class="headerlink" href="#video-2-latent-variable-models" title="Permalink to this headline"></a></h2>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "6e4c937f27904bd79ec6578ec12648fb"}
</script></div>
</div>
</div>
<div class="section" id="id4">
<h2>Submit your feedback<a class="headerlink" href="#id4" title="Permalink to this headline"></a></h2>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Submit your feedback</span>
<span class="n">content_review</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">feedback_prefix</span><span class="si">}</span><span class="s2">_Latent_Variable_Models_Video&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "278b8d44e8634c13bceab46805b9e4e4"}
</script></div>
</div>
<p>In the video, the concept of a latent variable model was introduced. We saw how PCA (principal component analysis) can be extended into a generative model with latent variables called probabilistic PCA (pPCA). For pPCA the latent variables (z in the video) are the projections onto the principal component axes.</p>
<p>The dimensionality of the principal components is typically set to be substantially lower-dimensional than the original data. Thus, the latent variables (the projection onto the principal component axes) are a lower-dimensional representation of the original data (dimensionality reduction!). With pPCA we can estimate the original distribution of the high dimensional data. This allows us to generate data with a distribution that looks more like the original data than if we were to only use PCA to generate data from the latent variables. Lets see how that might look with a simple example.</p>
</div>
<div class="section" id="bonus-coding-exercise-2-ppca">
<h2>(Bonus) Coding Exercise 2: pPCA<a class="headerlink" href="#bonus-coding-exercise-2-ppca" title="Permalink to this headline"></a></h2>
<p>Assume we have two noisy thermometers measuring the temperature of the same room. They both make noisy measurements.  The room tends to be around 25C (thats 77F), but can vary around that temperature.  If we take lots of readings from the two thermometers over time and plot the paired readings, we might see something like the plot generated below:</p>
<p>Generate example datapoints from the two thermometers</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @markdown Generate example datapoints from the two thermometers</span>

<span class="k">def</span> <span class="nf">generate_data</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">mean_of_temps</span><span class="p">,</span> <span class="n">cov_of_temps</span><span class="p">,</span> <span class="n">seed</span><span class="p">):</span>
<span class="w">  </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">  Generate random data, normally distributed</span>

<span class="sd">  Args:</span>
<span class="sd">    n_samples : int</span>
<span class="sd">      The number of samples to be generated</span>
<span class="sd">    mean_of_temps : numpy.ndarray</span>
<span class="sd">      1D array with the mean of temparatures, Kx1</span>
<span class="sd">    cov_of_temps : numpy.ndarray</span>
<span class="sd">      2D array with the covariance, , KxK</span>
<span class="sd">    seed : int</span>
<span class="sd">      Set random seed for the psudo random generator</span>

<span class="sd">  Returns:</span>
<span class="sd">    therm1 : numpy.ndarray</span>
<span class="sd">      Thermometer 1</span>
<span class="sd">    therm2 : numpy.ndarray</span>
<span class="sd">      Thermometer 2</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
  <span class="n">therm1</span><span class="p">,</span> <span class="n">therm2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">multivariate_normal</span><span class="p">(</span><span class="n">mean_of_temps</span><span class="p">,</span>
                                                <span class="n">cov_of_temps</span><span class="p">,</span>
                                                <span class="n">n_samples</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
  <span class="k">return</span> <span class="n">therm1</span><span class="p">,</span> <span class="n">therm2</span>


<span class="n">n_samples</span> <span class="o">=</span> <span class="mi">2000</span>
<span class="n">mean_of_temps</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">25</span><span class="p">,</span> <span class="mi">25</span><span class="p">])</span>
<span class="n">cov_of_temps</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">]])</span>
<span class="n">therm1</span><span class="p">,</span> <span class="n">therm2</span> <span class="o">=</span> <span class="n">generate_data</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">mean_of_temps</span><span class="p">,</span> <span class="n">cov_of_temps</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">therm1</span><span class="p">,</span> <span class="n">therm2</span><span class="p">,</span> <span class="s1">&#39;.&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;equal&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Thermometer 1 ($^\circ$C)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Thermometer 2 ($^\circ$C)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/W2D4_Tutorial1_60_0.png" src="../../../_images/W2D4_Tutorial1_60_0.png" />
</div>
</div>
<p>Lets model these data with a single principal component. Given that the thermometers are measuring the same actual temperature, the principal component axes will be the identity line. The direction of this axes can be indicated by the unit vector <span class="math notranslate nohighlight">\([1 ~~ 1]~/~\sqrt2\)</span>.  We could estimate this axes by applying PCA. We can plot this axes, it tells us something about the data, but we cant generate from it:</p>
<p>Add first PC axes to the plot</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @markdown Add first PC axes to the plot</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">therm1</span><span class="p">,</span> <span class="n">therm2</span><span class="p">,</span> <span class="s1">&#39;.&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;equal&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Thermometer 1 ($^\circ$C)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Thermometer 2 ($^\circ$C)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">()[</span><span class="mi">0</span><span class="p">],</span> <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">()[</span><span class="mi">1</span><span class="p">]],</span>
         <span class="p">[</span><span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">()[</span><span class="mi">0</span><span class="p">],</span> <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">()[</span><span class="mi">1</span><span class="p">]])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/W2D4_Tutorial1_63_0.png" src="../../../_images/W2D4_Tutorial1_63_0.png" />
</div>
</div>
<p><strong>Step 1:</strong> Calculate the parameters of the pPCA model</p>
<p>This part is completed already, so you dont need to make any edits:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Project Data onto the principal component axes.</span>
<span class="c1"># We could have &quot;learned&quot; this from the data by applying PCA,</span>
<span class="c1"># but we &quot;know&quot; the value from the problem definition.</span>
<span class="n">pc_axes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">])</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mf">2.0</span><span class="p">)</span>

<span class="c1"># Thermometers data</span>
<span class="n">therm_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">therm1</span><span class="p">,</span> <span class="n">therm2</span><span class="p">])</span>

<span class="c1"># Zero center the data</span>
<span class="n">therm_data_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">therm_data</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">therm_data_center</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">outer</span><span class="p">(</span><span class="n">therm_data_mean</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">therm_data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
<span class="n">therm_data_zero_centered</span> <span class="o">=</span> <span class="n">therm_data</span> <span class="o">-</span> <span class="n">therm_data_center</span>

<span class="c1"># Calculate the variance of the projection on the PC axes</span>
<span class="n">pc_projection</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">pc_axes</span><span class="p">,</span> <span class="n">therm_data_zero_centered</span><span class="p">);</span>
<span class="n">pc_axes_variance</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">pc_projection</span><span class="p">)</span>

<span class="c1"># Calculate the residual variance (variance not accounted for by projection on the PC axes)</span>
<span class="n">sensor_noise_std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">therm_data_zero_centered</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">outer</span><span class="p">(</span><span class="n">pc_axes</span><span class="p">,</span> <span class="n">pc_projection</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="nb">ord</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
<span class="n">sensor_noise_var</span> <span class="o">=</span> <span class="n">sensor_noise_std</span> <span class="o">**</span><span class="mi">2</span>
</pre></div>
</div>
</div>
</div>
<p><strong>Step 2</strong>: Generate from the pPCA model of the thermometer data.</p>
<p>Complete the code so we generate data by sampling according to the pPCA model:</p>
<div class="amsmath math notranslate nohighlight" id="equation-c9e1d983-65a9-4740-9e1a-d95db6e88cf8">
<span class="eqno">(86)<a class="headerlink" href="#equation-c9e1d983-65a9-4740-9e1a-d95db6e88cf8" title="Permalink to this equation"></a></span>\[\begin{equation}
x = \mu + W z + \epsilon, \,\text{where}\,~~ \epsilon \sim \mathcal{N}(0,~\sigma^2 \mathbf{I})
\end{equation}\]</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">gen_from_pPCA</span><span class="p">(</span><span class="n">noise_var</span><span class="p">,</span> <span class="n">data_mean</span><span class="p">,</span> <span class="n">pc_axes</span><span class="p">,</span> <span class="n">pc_variance</span><span class="p">):</span>
<span class="w">  </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">  Generate samples from pPCA</span>

<span class="sd">  Args:</span>
<span class="sd">    noise_var: np.ndarray</span>
<span class="sd">      Sensor noise variance</span>
<span class="sd">    data_mean: np.ndarray</span>
<span class="sd">      Thermometer data mean</span>
<span class="sd">    pc_axes: np.ndarray</span>
<span class="sd">      Principal component axes</span>
<span class="sd">    pc_variance: np.ndarray</span>
<span class="sd">      The variance of the projection on the PC axes</span>

<span class="sd">  Returns:</span>
<span class="sd">    therm_data_sim: np.ndarray</span>
<span class="sd">      Generated (simulate, draw) `n_samples` from pPCA model</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="c1"># We are matching this value to the thermometer data so the visualizations look similar</span>
  <span class="n">n_samples</span> <span class="o">=</span> <span class="mi">1000</span>

  <span class="c1"># Randomly sample from z (latent space value)</span>
  <span class="n">z</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">pc_variance</span><span class="p">),</span> <span class="n">n_samples</span><span class="p">)</span>

  <span class="c1"># Sensor noise covariance matrix ()</span>
  <span class="n">epsilon_cov</span> <span class="o">=</span> <span class="p">[[</span><span class="n">noise_var</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">noise_var</span><span class="p">]]</span>

  <span class="c1"># Data mean reshaped for the generation</span>
  <span class="n">sim_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">outer</span><span class="p">(</span><span class="n">data_mean</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">n_samples</span><span class="p">))</span>

  <span class="c1">####################################################################</span>
  <span class="c1"># Fill in all missing code below (...),</span>
  <span class="c1"># then remove or comment the line below to test your class</span>
  <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;Please complete the `gen_from_pPCA` function&quot;</span><span class="p">)</span>
  <span class="c1">####################################################################</span>
  <span class="c1"># Draw `n_samples` from `np.random.multivariate_normal`</span>
  <span class="n">rand_eps</span> <span class="o">=</span> <span class="o">...</span>
  <span class="n">rand_eps</span> <span class="o">=</span> <span class="n">rand_eps</span><span class="o">.</span><span class="n">T</span>

  <span class="c1"># Generate (simulate, draw) `n_samples` from pPCA model</span>
  <span class="n">therm_data_sim</span> <span class="o">=</span> <span class="o">...</span>

  <span class="k">return</span> <span class="n">therm_data_sim</span>



<span class="c1">## Uncomment to test your code</span>
<span class="c1"># therm_data_sim = gen_from_pPCA(sensor_noise_var, therm_data_mean, pc_axes, pc_axes_variance)</span>
<span class="c1"># plot_gen_samples_ppca(therm1, therm2, therm_data_sim)</span>
</pre></div>
</div>
</div>
</div>
<p><a class="reference external" href="https://github.com/NeuromatchAcademy/course-content-dl/tree/main/tutorials/W2D4_GenerativeModels/solutions/W2D4_Tutorial1_Solution_3b0c285b.py"><em>Click for solution</em></a></p>
<div class="section" id="id5">
<h3>Submit your feedback<a class="headerlink" href="#id5" title="Permalink to this headline"></a></h3>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Submit your feedback</span>
<span class="n">content_review</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">feedback_prefix</span><span class="si">}</span><span class="s2">_Coding_pPCA_Exercise&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "1c2dc47a3fd6403f91d58ae5e37f8c9d"}
</script></div>
</div>
</div>
</div>
</div>
<hr class="docutils" />
<div class="section" id="section-3-autoencoders">
<h1>Section 3: Autoencoders<a class="headerlink" href="#section-3-autoencoders" title="Permalink to this headline"></a></h1>
<p><em>Time estimate: ~30mins</em></p>
<p><strong>Please</strong> run the cell after the video to download MNIST and CIFAR10 image datasets while the video plays.</p>
<div class="section" id="video-3-autoencoders">
<h2>Video 3: Autoencoders<a class="headerlink" href="#video-3-autoencoders" title="Permalink to this headline"></a></h2>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "01674f9c07bb411fb16d36373fd5bec6"}
</script></div>
</div>
</div>
<div class="section" id="id6">
<h2>Submit your feedback<a class="headerlink" href="#id6" title="Permalink to this headline"></a></h2>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Submit your feedback</span>
<span class="n">content_review</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">feedback_prefix</span><span class="si">}</span><span class="s2">_Autoencoders_Video&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "bad92460c1c9469390561e3aebb03aeb"}
</script></div>
</div>
<p>Download MNIST and CIFAR10 datasets</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @markdown Download MNIST and CIFAR10 datasets</span>
<span class="kn">import</span> <span class="nn">tarfile</span><span class="o">,</span> <span class="nn">requests</span><span class="o">,</span> <span class="nn">os</span>

<span class="n">fname</span> <span class="o">=</span> <span class="s1">&#39;MNIST.tar.gz&#39;</span>
<span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;mnist&#39;</span>
<span class="n">url</span> <span class="o">=</span> <span class="s1">&#39;https://osf.io/y2fj6/download&#39;</span>

<span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">name</span><span class="p">):</span>
  <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Downloading MNIST dataset...&#39;</span><span class="p">)</span>
  <span class="n">r</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">allow_redirects</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
  <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">fname</span><span class="p">,</span> <span class="s1">&#39;wb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">fh</span><span class="p">:</span>
    <span class="n">fh</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">r</span><span class="o">.</span><span class="n">content</span><span class="p">)</span>
  <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Downloading MNIST completed!</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">name</span><span class="p">):</span>
  <span class="k">with</span> <span class="n">tarfile</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">fname</span><span class="p">)</span> <span class="k">as</span> <span class="n">tar</span><span class="p">:</span>
    <span class="n">tar</span><span class="o">.</span><span class="n">extractall</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>
    <span class="n">os</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">fname</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
  <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;MNIST dataset has been downloaded.</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>


<span class="n">fname</span> <span class="o">=</span> <span class="s1">&#39;cifar-10-python.tar.gz&#39;</span>
<span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;cifar10&#39;</span>
<span class="n">url</span> <span class="o">=</span> <span class="s1">&#39;https://osf.io/jbpme/download&#39;</span>

<span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">name</span><span class="p">):</span>
  <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Downloading CIFAR10 dataset...&#39;</span><span class="p">)</span>
  <span class="n">r</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">allow_redirects</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
  <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">fname</span><span class="p">,</span> <span class="s1">&#39;wb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">fh</span><span class="p">:</span>
    <span class="n">fh</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">r</span><span class="o">.</span><span class="n">content</span><span class="p">)</span>
  <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Downloading CIFAR10 completed!&#39;</span><span class="p">)</span>

<span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">name</span><span class="p">):</span>
  <span class="k">with</span> <span class="n">tarfile</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">fname</span><span class="p">)</span> <span class="k">as</span> <span class="n">tar</span><span class="p">:</span>
    <span class="n">tar</span><span class="o">.</span><span class="n">extractall</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>
    <span class="n">os</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">fname</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
  <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;CIFAR10 dataset has been dowloaded.&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Downloading MNIST dataset...
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Downloading MNIST completed!
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Downloading CIFAR10 dataset...
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Downloading CIFAR10 completed!
</pre></div>
</div>
</div>
</div>
<p>Load MNIST and CIFAR10 image datasets</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @markdown Load MNIST and CIFAR10 image datasets</span>
<span class="c1"># See https://pytorch.org/docs/stable/torchvision/datasets.html</span>

<span class="c1"># MNIST</span>
<span class="n">mnist</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="s1">&#39;./mnist/&#39;</span><span class="p">,</span>
                       <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                       <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
                       <span class="n">download</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">mnist_val</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="s1">&#39;./mnist/&#39;</span><span class="p">,</span>
                           <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                           <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
                           <span class="n">download</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># CIFAR 10</span>
<span class="n">cifar10</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">CIFAR10</span><span class="p">(</span><span class="s1">&#39;./cifar10/&#39;</span><span class="p">,</span>
                           <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                           <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
                           <span class="n">download</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">cifar10_val</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">CIFAR10</span><span class="p">(</span><span class="s1">&#39;./cifar10/&#39;</span><span class="p">,</span>
                               <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                               <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
                               <span class="n">download</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="select-a-dataset">
<h3>Select a dataset<a class="headerlink" href="#select-a-dataset" title="Permalink to this headline"></a></h3>
<p>Weve built todays tutorial to be flexible. It should work more-or-less out of the box with both MNIST and CIFAR (and other image datasets). MNIST is in many ways simpler, and the results will likely look better and run a bit faster if using MNIST. But we are leaving it up to you to pick which one you want to experiment with!</p>
<p>We encourage pods to coordinate so that some members use MNIST and others use CIFAR10. Keep in mind that the CIFAR dataset may require more learning epochs (longer training required).</p>
<p>Change the variable <code class="docutils literal notranslate"><span class="pre">dataset_name</span></code> below to pick your dataset.</p>
<p>Execute this cell to enable helper function <code class="docutils literal notranslate"><span class="pre">get_data</span></code></p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @markdown Execute this cell to enable helper function `get_data`</span>

<span class="k">def</span> <span class="nf">get_data</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;mnist&#39;</span><span class="p">):</span>
<span class="w">  </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">  Get data</span>

<span class="sd">  Args:</span>
<span class="sd">    name: string</span>
<span class="sd">      Name of the dataset</span>

<span class="sd">  Returns:</span>
<span class="sd">    my_dataset: dataset instance</span>
<span class="sd">      Instance of dataset</span>
<span class="sd">    my_dataset_name: string</span>
<span class="sd">      Name of the dataset</span>
<span class="sd">    my_dataset_shape: tuple</span>
<span class="sd">      Shape of dataset</span>
<span class="sd">    my_dataset_size: int</span>
<span class="sd">      Size of dataset</span>
<span class="sd">    my_valset: torch.loader</span>
<span class="sd">      Validation loader</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">if</span> <span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;mnist&#39;</span><span class="p">:</span>
    <span class="n">my_dataset_name</span> <span class="o">=</span> <span class="s2">&quot;MNIST&quot;</span>
    <span class="n">my_dataset</span> <span class="o">=</span> <span class="n">mnist</span>
    <span class="n">my_valset</span> <span class="o">=</span> <span class="n">mnist_val</span>
    <span class="n">my_dataset_shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">)</span>
    <span class="n">my_dataset_size</span> <span class="o">=</span> <span class="mi">28</span> <span class="o">*</span> <span class="mi">28</span>
  <span class="k">elif</span> <span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;cifar10&#39;</span><span class="p">:</span>
    <span class="n">my_dataset_name</span> <span class="o">=</span> <span class="s2">&quot;CIFAR10&quot;</span>
    <span class="n">my_dataset</span> <span class="o">=</span> <span class="n">cifar10</span>
    <span class="n">my_valset</span> <span class="o">=</span> <span class="n">cifar10_val</span>
    <span class="n">my_dataset_shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
    <span class="n">my_dataset_size</span> <span class="o">=</span> <span class="mi">3</span> <span class="o">*</span> <span class="mi">32</span> <span class="o">*</span> <span class="mi">32</span>

  <span class="k">return</span> <span class="n">my_dataset</span><span class="p">,</span> <span class="n">my_dataset_name</span><span class="p">,</span> <span class="n">my_dataset_shape</span><span class="p">,</span> <span class="n">my_dataset_size</span><span class="p">,</span> <span class="n">my_valset</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dataset_name</span> <span class="o">=</span> <span class="s1">&#39;mnist&#39;</span>  <span class="c1"># This can be mnist or cifar10</span>
<span class="n">train_set</span><span class="p">,</span> <span class="n">dataset_name</span><span class="p">,</span> <span class="n">data_shape</span><span class="p">,</span> <span class="n">data_size</span><span class="p">,</span> <span class="n">valid_set</span> <span class="o">=</span> <span class="n">get_data</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="n">dataset_name</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="section-3-1-conceptual-introduction-to-autoencoders">
<h2>Section 3.1: Conceptual introduction to AutoEncoders<a class="headerlink" href="#section-3-1-conceptual-introduction-to-autoencoders" title="Permalink to this headline"></a></h2>
<p>Now well create our first autoencoder. It will reduce images down to <span class="math notranslate nohighlight">\(K\)</span> dimensions. The architecture will be quite simple: the input will be linearly mapped to a single hidden (or latent) layer <span class="math notranslate nohighlight">\(\mathbf{h}\)</span> with <span class="math notranslate nohighlight">\(K\)</span> units, which will then be linearly mapped back to an output that is the same size as the input:</p>
<div class="amsmath math notranslate nohighlight" id="equation-c4bef01b-1748-4b2b-bb9c-63c51f1977e8">
<span class="eqno">(87)<a class="headerlink" href="#equation-c4bef01b-1748-4b2b-bb9c-63c51f1977e8" title="Permalink to this equation"></a></span>\[\begin{equation}
\mathbf{x} \longrightarrow \mathbf{h} \longrightarrow \mathbf{x'}
\end{equation}\]</div>
<p>The loss function well use will simply be mean squared error (MSE) quantifying how well the reconstruction (<span class="math notranslate nohighlight">\(\mathbf{x'}\)</span>) matches the original image (<span class="math notranslate nohighlight">\(\mathbf{x}\)</span>):</p>
<div class="amsmath math notranslate nohighlight" id="equation-80949a14-3c52-47f8-ba6a-40f7dc183844">
<span class="eqno">(88)<a class="headerlink" href="#equation-80949a14-3c52-47f8-ba6a-40f7dc183844" title="Permalink to this equation"></a></span>\[\begin{equation}
\text{MSE Loss} = \sum_{i=1}^{N} ||\mathbf{x}_i - \mathbf{x'}_i||^2_2
\end{equation}\]</div>
<p>If all goes well, then the AutoEncoder will learn, <strong>end to end</strong>, a good encoding or compression of inputs to a latent representation (<span class="math notranslate nohighlight">\(\mathbf{x \longrightarrow h}\)</span>) as well as a good decoding of that latent representation to a reconstruction of the original input (<span class="math notranslate nohighlight">\(\mathbf{h \longrightarrow x'}\)</span>).</p>
<p>We first need to choose our desired dimensionality of <span class="math notranslate nohighlight">\(\mathbf{h}\)</span>. Well see more on this below, but for MNIST, 5 to 20 is plenty. For CIFAR, we need more like 50 to 100 dimensions.</p>
<p>Coordinate with your pod to try a variety of values for <span class="math notranslate nohighlight">\(K\)</span> in each dataset so you can compare results.</p>
<div class="section" id="coding-exercise-3-1-linear-autoencoder-architecture">
<h3>Coding Exercise 3.1: Linear AutoEncoder Architecture<a class="headerlink" href="#coding-exercise-3-1-linear-autoencoder-architecture" title="Permalink to this headline"></a></h3>
<p>Complete the missing parts of the <code class="docutils literal notranslate"><span class="pre">LinearAutoEncoder</span></code> class. Were back to using PyTorch in this exercise.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">LinearAutoEncoder</span></code> as two stages: an <code class="docutils literal notranslate"><span class="pre">encoder</span></code> which linearly maps from inputs of size <code class="docutils literal notranslate"><span class="pre">x_dim</span> <span class="pre">=</span> <span class="pre">my_dataset_dim</span></code> to a hidden layer of size <code class="docutils literal notranslate"><span class="pre">h_dim</span> <span class="pre">=</span> <span class="pre">K</span></code> (with no nonlinearity), and a <code class="docutils literal notranslate"><span class="pre">decoder</span></code> which maps back from <code class="docutils literal notranslate"><span class="pre">K</span></code> up to the number of pixels in each image.</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @markdown #### Run to define the `train_autoencoder` function.</span>
<span class="c1"># @markdown Feel free to inspect the training function if the time allows.</span>

<span class="c1"># @markdown `train_autoencoder(autoencoder, dataset, device, epochs=20, batch_size=250, seed=0)`</span>


<span class="k">def</span> <span class="nf">train_autoencoder</span><span class="p">(</span><span class="n">autoencoder</span><span class="p">,</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">250</span><span class="p">,</span>
                      <span class="n">seed</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
<span class="w">  </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">  Function to train autoencoder</span>

<span class="sd">  Args:</span>
<span class="sd">    autoencoder: nn.module</span>
<span class="sd">      Autoencoder instance</span>
<span class="sd">    dataset: function</span>
<span class="sd">      Dataset</span>
<span class="sd">    device: string</span>
<span class="sd">      GPU if available. CPU otherwise</span>
<span class="sd">    epochs: int</span>
<span class="sd">      Number of epochs [default: 20]</span>
<span class="sd">    batch_size: int</span>
<span class="sd">      Batch size</span>
<span class="sd">    seed: int</span>
<span class="sd">      Set seed for reproducibility; [default: 0]</span>

<span class="sd">  Returns:</span>
<span class="sd">    mse_loss: float</span>
<span class="sd">      MSE Loss</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">autoencoder</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
  <span class="n">optim</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">autoencoder</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span>
                           <span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span>
                           <span class="n">weight_decay</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">)</span>
  <span class="n">loss_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>
  <span class="n">g_seed</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Generator</span><span class="p">()</span>
  <span class="n">g_seed</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
  <span class="n">loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span>
                      <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
                      <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                      <span class="n">pin_memory</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                      <span class="n">num_workers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                      <span class="n">worker_init_fn</span><span class="o">=</span><span class="n">seed_worker</span><span class="p">,</span>
                      <span class="n">generator</span><span class="o">=</span><span class="n">g_seed</span><span class="p">)</span>

  <span class="n">mse_loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">epochs</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span> <span class="o">//</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
  <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="n">trange</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="s1">&#39;Epoch&#39;</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">im_batch</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">loader</span><span class="p">:</span>
      <span class="n">im_batch</span> <span class="o">=</span> <span class="n">im_batch</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
      <span class="n">optim</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
      <span class="n">reconstruction</span> <span class="o">=</span> <span class="n">autoencoder</span><span class="p">(</span><span class="n">im_batch</span><span class="p">)</span>
      <span class="c1"># Loss calculation</span>
      <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">reconstruction</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
                     <span class="n">target</span><span class="o">=</span><span class="n">im_batch</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
      <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
      <span class="n">optim</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

      <span class="n">mse_loss</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">loss</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
      <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>
  <span class="c1"># After training completes,</span>
  <span class="c1"># make sure the model is on CPU so we can easily</span>
  <span class="c1"># do more visualizations and demos.</span>
  <span class="n">autoencoder</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">mse_loss</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">LinearAutoEncoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">  </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">  Linear Autoencoder</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x_dim</span><span class="p">,</span> <span class="n">h_dim</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A Linear AutoEncoder</span>

<span class="sd">    Args:</span>
<span class="sd">      x_dim: int</span>
<span class="sd">        Input dimension</span>
<span class="sd">      h_dim: int</span>
<span class="sd">        Hidden dimension, bottleneck dimension, K</span>

<span class="sd">    Returns:</span>
<span class="sd">      Nothing</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="c1">####################################################################</span>
    <span class="c1"># Fill in all missing code below (...),</span>
    <span class="c1"># then remove or comment the line below to test your class</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;Please complete the LinearAutoEncoder class!&quot;</span><span class="p">)</span>
    <span class="c1">####################################################################</span>
    <span class="c1"># Encoder layer (a linear mapping from x_dim to K)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">enc_lin</span> <span class="o">=</span> <span class="o">...</span>
    <span class="c1"># Decoder layer (a linear mapping from K to x_dim)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dec_lin</span> <span class="o">=</span> <span class="o">...</span>

  <span class="k">def</span> <span class="nf">encode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Encoder function</span>

<span class="sd">    Args:</span>
<span class="sd">      x: torch.tensor</span>
<span class="sd">        Input features</span>

<span class="sd">    Returns:</span>
<span class="sd">      x: torch.tensor</span>
<span class="sd">        Encoded output</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1">####################################################################</span>
    <span class="c1"># Fill in all missing code below (...),</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;Please complete the `encode` function!&quot;</span><span class="p">)</span>
    <span class="c1">####################################################################</span>
    <span class="n">h</span> <span class="o">=</span> <span class="o">...</span>
    <span class="k">return</span> <span class="n">h</span>

  <span class="k">def</span> <span class="nf">decode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">h</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Decoder function</span>

<span class="sd">    Args:</span>
<span class="sd">      h: torch.tensor</span>
<span class="sd">        Encoded output</span>

<span class="sd">    Returns:</span>
<span class="sd">      x_prime: torch.tensor</span>
<span class="sd">        Decoded output</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1">####################################################################</span>
    <span class="c1"># Fill in all missing code below (...),</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;Please complete the `decode` function!&quot;</span><span class="p">)</span>
    <span class="c1">####################################################################</span>
    <span class="n">x_prime</span> <span class="o">=</span> <span class="o">...</span>
    <span class="k">return</span> <span class="n">x_prime</span>

  <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Forward pass</span>

<span class="sd">    Args:</span>
<span class="sd">      x: torch.tensor</span>
<span class="sd">        Input data</span>

<span class="sd">    Returns:</span>
<span class="sd">      Decoded output</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">flat_x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">h</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">flat_x</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">h</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>



<span class="c1"># Pick your own K</span>
<span class="n">K</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">set_seed</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>
<span class="c1">## Uncomment to test your code</span>
<span class="c1"># lin_ae = LinearAutoEncoder(data_size, K)</span>
<span class="c1"># lin_losses = train_autoencoder(lin_ae, train_set, device=DEVICE, seed=SEED)</span>
<span class="c1"># plot_linear_ae(lin_losses)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Random seed 2021 has been set.
</pre></div>
</div>
</div>
</div>
<p><a class="reference external" href="https://github.com/NeuromatchAcademy/course-content-dl/tree/main/tutorials/W2D4_GenerativeModels/solutions/W2D4_Tutorial1_Solution_3872c34f.py"><em>Click for solution</em></a></p>
<div class="section" id="id7">
<h4>Submit your feedback<a class="headerlink" href="#id7" title="Permalink to this headline"></a></h4>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Submit your feedback</span>
<span class="n">content_review</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">feedback_prefix</span><span class="si">}</span><span class="s2">_Linear_Autoencoder_Exercise&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "356b754c6a254da58df3828881cc3fbc"}
</script></div>
</div>
</div>
</div>
<div class="section" id="comparison-to-pca">
<h3>Comparison to PCA<a class="headerlink" href="#comparison-to-pca" title="Permalink to this headline"></a></h3>
<p>One way to think about AutoEncoders is as a form of dimensionality-reduction. The dimensionality of <span class="math notranslate nohighlight">\(\mathbf{h}\)</span> is much smaller than the dimensionality of <span class="math notranslate nohighlight">\(\mathbf{x}\)</span>.</p>
<p>Another common technique for dimensionality reduction is to project data onto the top <span class="math notranslate nohighlight">\(K\)</span> <strong>principal components</strong> (Principal Component Analysis or PCA). For comparison, lets also apply PCA for dimensionality reduction. The following cell will do this using the same value of K as you chose for the linear autoencoder.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># PCA requires finding the top K eigenvectors of the data covariance. Start by</span>
<span class="c1"># finding the mean and covariance of the pixels in our dataset</span>
<span class="n">g_seed</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Generator</span><span class="p">()</span>
<span class="n">g_seed</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">SEED</span><span class="p">)</span>

<span class="n">loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_set</span><span class="p">,</span>
                    <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>
                    <span class="n">pin_memory</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                    <span class="n">num_workers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                    <span class="n">worker_init_fn</span><span class="o">=</span><span class="n">seed_worker</span><span class="p">,</span>
                    <span class="n">generator</span><span class="o">=</span><span class="n">g_seed</span><span class="p">)</span>

<span class="n">mu</span><span class="p">,</span> <span class="n">cov</span> <span class="o">=</span> <span class="n">image_moments</span><span class="p">((</span><span class="n">im</span> <span class="k">for</span> <span class="n">im</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">loader</span><span class="p">),</span>
                        <span class="n">n_batches</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">train_set</span><span class="p">)</span> <span class="o">//</span> <span class="mi">32</span><span class="p">)</span>

<span class="n">pca_encode</span><span class="p">,</span> <span class="n">pca_decode</span> <span class="o">=</span> <span class="n">pca_encoder_decoder</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">cov</span><span class="p">,</span> <span class="n">K</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "864593702bb84047a820b3f3b77d5012"}
</script><div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">RuntimeError</span><span class="g g-Whitespace">                              </span>Traceback (most recent call last)
<span class="nn">File ~/opt/anaconda3/envs/nma-course/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1132,</span> in <span class="ni">_MultiProcessingDataLoaderIter._try_get_data</span><span class="nt">(self, timeout)</span>
<span class="g g-Whitespace">   </span><span class="mi">1131</span> <span class="k">try</span><span class="p">:</span>
<span class="ne">-&gt; </span><span class="mi">1132</span>     <span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_data_queue</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">timeout</span><span class="o">=</span><span class="n">timeout</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1133</span>     <span class="k">return</span> <span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>

<span class="nn">File ~/opt/anaconda3/envs/nma-course/lib/python3.9/multiprocessing/queues.py:113,</span> in <span class="ni">Queue.get</span><span class="nt">(self, block, timeout)</span>
<span class="g g-Whitespace">    </span><span class="mi">112</span> <span class="n">timeout</span> <span class="o">=</span> <span class="n">deadline</span> <span class="o">-</span> <span class="n">time</span><span class="o">.</span><span class="n">monotonic</span><span class="p">()</span>
<span class="ne">--&gt; </span><span class="mi">113</span> <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_poll</span><span class="p">(</span><span class="n">timeout</span><span class="p">):</span>
<span class="g g-Whitespace">    </span><span class="mi">114</span>     <span class="k">raise</span> <span class="n">Empty</span>

<span class="nn">File ~/opt/anaconda3/envs/nma-course/lib/python3.9/multiprocessing/connection.py:257,</span> in <span class="ni">_ConnectionBase.poll</span><span class="nt">(self, timeout)</span>
<span class="g g-Whitespace">    </span><span class="mi">256</span> <span class="bp">self</span><span class="o">.</span><span class="n">_check_readable</span><span class="p">()</span>
<span class="ne">--&gt; </span><span class="mi">257</span> <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_poll</span><span class="p">(</span><span class="n">timeout</span><span class="p">)</span>

<span class="nn">File ~/opt/anaconda3/envs/nma-course/lib/python3.9/multiprocessing/connection.py:424,</span> in <span class="ni">Connection._poll</span><span class="nt">(self, timeout)</span>
<span class="g g-Whitespace">    </span><span class="mi">423</span> <span class="k">def</span> <span class="nf">_poll</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">timeout</span><span class="p">):</span>
<span class="ne">--&gt; </span><span class="mi">424</span>     <span class="n">r</span> <span class="o">=</span> <span class="n">wait</span><span class="p">([</span><span class="bp">self</span><span class="p">],</span> <span class="n">timeout</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">425</span>     <span class="k">return</span> <span class="nb">bool</span><span class="p">(</span><span class="n">r</span><span class="p">)</span>

<span class="nn">File ~/opt/anaconda3/envs/nma-course/lib/python3.9/multiprocessing/connection.py:931,</span> in <span class="ni">wait</span><span class="nt">(object_list, timeout)</span>
<span class="g g-Whitespace">    </span><span class="mi">930</span> <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">931</span>     <span class="n">ready</span> <span class="o">=</span> <span class="n">selector</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="n">timeout</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">932</span>     <span class="k">if</span> <span class="n">ready</span><span class="p">:</span>

<span class="nn">File ~/opt/anaconda3/envs/nma-course/lib/python3.9/selectors.py:416,</span> in <span class="ni">_PollLikeSelector.select</span><span class="nt">(self, timeout)</span>
<span class="g g-Whitespace">    </span><span class="mi">415</span> <span class="k">try</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">416</span>     <span class="n">fd_event_list</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_selector</span><span class="o">.</span><span class="n">poll</span><span class="p">(</span><span class="n">timeout</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">417</span> <span class="k">except</span> <span class="ne">InterruptedError</span><span class="p">:</span>

<span class="nn">File ~/opt/anaconda3/envs/nma-course/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py:66,</span> in <span class="ni">_set_SIGCHLD_handler.&lt;locals&gt;.handler</span><span class="nt">(signum, frame)</span>
<span class="g g-Whitespace">     </span><span class="mi">63</span> <span class="k">def</span> <span class="nf">handler</span><span class="p">(</span><span class="n">signum</span><span class="p">,</span> <span class="n">frame</span><span class="p">):</span>
<span class="g g-Whitespace">     </span><span class="mi">64</span>     <span class="c1"># This following call uses `waitid` with WNOHANG from C side. Therefore,</span>
<span class="g g-Whitespace">     </span><span class="mi">65</span>     <span class="c1"># Python can still get and update the process status successfully.</span>
<span class="ne">---&gt; </span><span class="mi">66</span>     <span class="n">_error_if_any_worker_fails</span><span class="p">()</span>
<span class="g g-Whitespace">     </span><span class="mi">67</span>     <span class="k">if</span> <span class="n">previous_handler</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>

<span class="ne">RuntimeError</span>: DataLoader worker (pid 76890) exited unexpectedly with exit code 1. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace.

<span class="n">The</span> <span class="n">above</span> <span class="n">exception</span> <span class="n">was</span> <span class="n">the</span> <span class="n">direct</span> <span class="n">cause</span> <span class="n">of</span> <span class="n">the</span> <span class="n">following</span> <span class="n">exception</span><span class="p">:</span>

<span class="ne">RuntimeError</span><span class="g g-Whitespace">                              </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span><span class="p">[</span><span class="mi">36</span><span class="p">],</span> <span class="n">line</span> <span class="mi">13</span>
<span class="g g-Whitespace">      </span><span class="mi">4</span> <span class="n">g_seed</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">SEED</span><span class="p">)</span>
<span class="g g-Whitespace">      </span><span class="mi">6</span> <span class="n">loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_set</span><span class="p">,</span>
<span class="g g-Whitespace">      </span><span class="mi">7</span>                     <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>
<span class="g g-Whitespace">      </span><span class="mi">8</span>                     <span class="n">pin_memory</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="g g-Whitespace">      </span><span class="mi">9</span>                     <span class="n">num_workers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
<span class="g g-Whitespace">     </span><span class="mi">10</span>                     <span class="n">worker_init_fn</span><span class="o">=</span><span class="n">seed_worker</span><span class="p">,</span>
<span class="g g-Whitespace">     </span><span class="mi">11</span>                     <span class="n">generator</span><span class="o">=</span><span class="n">g_seed</span><span class="p">)</span>
<span class="ne">---&gt; </span><span class="mi">13</span> <span class="n">mu</span><span class="p">,</span> <span class="n">cov</span> <span class="o">=</span> <span class="n">image_moments</span><span class="p">((</span><span class="n">im</span> <span class="k">for</span> <span class="n">im</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">loader</span><span class="p">),</span>
<span class="g g-Whitespace">     </span><span class="mi">14</span>                         <span class="n">n_batches</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">train_set</span><span class="p">)</span> <span class="o">//</span> <span class="mi">32</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">16</span> <span class="n">pca_encode</span><span class="p">,</span> <span class="n">pca_decode</span> <span class="o">=</span> <span class="n">pca_encoder_decoder</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">cov</span><span class="p">,</span> <span class="n">K</span><span class="p">)</span>

<span class="nn">Cell In[6], line 23,</span> in <span class="ni">image_moments</span><span class="nt">(image_batches, n_batches)</span>
<span class="g g-Whitespace">     </span><span class="mi">21</span> <span class="n">m1</span><span class="p">,</span> <span class="n">m2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((),</span> <span class="n">device</span><span class="o">=</span><span class="n">DEVICE</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((),</span> <span class="n">device</span><span class="o">=</span><span class="n">DEVICE</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">22</span> <span class="n">n</span> <span class="o">=</span> <span class="mi">0</span>
<span class="ne">---&gt; </span><span class="mi">23</span> <span class="k">for</span> <span class="n">im</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">image_batches</span><span class="p">,</span> <span class="n">total</span><span class="o">=</span><span class="n">n_batches</span><span class="p">,</span> <span class="n">leave</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="g g-Whitespace">     </span><span class="mi">24</span>                <span class="n">desc</span><span class="o">=</span><span class="s1">&#39;Computing pixel mean and covariance...&#39;</span><span class="p">):</span>
<span class="g g-Whitespace">     </span><span class="mi">25</span>   <span class="n">im</span> <span class="o">=</span> <span class="n">im</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">26</span>   <span class="n">b</span> <span class="o">=</span> <span class="n">im</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>

<span class="nn">File ~/opt/anaconda3/envs/nma-course/lib/python3.9/site-packages/tqdm/notebook.py:254,</span> in <span class="ni">tqdm_notebook.__iter__</span><span class="nt">(self)</span>
<span class="g g-Whitespace">    </span><span class="mi">252</span> <span class="k">try</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">253</span>     <span class="n">it</span> <span class="o">=</span> <span class="nb">super</span><span class="p">(</span><span class="n">tqdm_notebook</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__iter__</span><span class="p">()</span>
<span class="ne">--&gt; </span><span class="mi">254</span>     <span class="k">for</span> <span class="n">obj</span> <span class="ow">in</span> <span class="n">it</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">255</span>         <span class="c1"># return super(tqdm...) will not catch exception</span>
<span class="g g-Whitespace">    </span><span class="mi">256</span>         <span class="k">yield</span> <span class="n">obj</span>
<span class="g g-Whitespace">    </span><span class="mi">257</span> <span class="c1"># NB: except ... [ as ...] breaks IPython async KeyboardInterrupt</span>

<span class="nn">File ~/opt/anaconda3/envs/nma-course/lib/python3.9/site-packages/tqdm/std.py:1178,</span> in <span class="ni">tqdm.__iter__</span><span class="nt">(self)</span>
<span class="g g-Whitespace">   </span><span class="mi">1175</span> <span class="n">time</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_time</span>
<span class="g g-Whitespace">   </span><span class="mi">1177</span> <span class="k">try</span><span class="p">:</span>
<span class="ne">-&gt; </span><span class="mi">1178</span>     <span class="k">for</span> <span class="n">obj</span> <span class="ow">in</span> <span class="n">iterable</span><span class="p">:</span>
<span class="g g-Whitespace">   </span><span class="mi">1179</span>         <span class="k">yield</span> <span class="n">obj</span>
<span class="g g-Whitespace">   </span><span class="mi">1180</span>         <span class="c1"># Update and possibly print the progressbar.</span>
<span class="g g-Whitespace">   </span><span class="mi">1181</span>         <span class="c1"># Note: does not call self.update(1) for speed optimisation.</span>

<span class="nn">Cell In[36], line 13,</span> in <span class="ni">&lt;genexpr&gt;</span><span class="nt">(.0)</span>
<span class="g g-Whitespace">      </span><span class="mi">4</span> <span class="n">g_seed</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">SEED</span><span class="p">)</span>
<span class="g g-Whitespace">      </span><span class="mi">6</span> <span class="n">loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_set</span><span class="p">,</span>
<span class="g g-Whitespace">      </span><span class="mi">7</span>                     <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>
<span class="g g-Whitespace">      </span><span class="mi">8</span>                     <span class="n">pin_memory</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="g g-Whitespace">      </span><span class="mi">9</span>                     <span class="n">num_workers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
<span class="g g-Whitespace">     </span><span class="mi">10</span>                     <span class="n">worker_init_fn</span><span class="o">=</span><span class="n">seed_worker</span><span class="p">,</span>
<span class="g g-Whitespace">     </span><span class="mi">11</span>                     <span class="n">generator</span><span class="o">=</span><span class="n">g_seed</span><span class="p">)</span>
<span class="ne">---&gt; </span><span class="mi">13</span> <span class="n">mu</span><span class="p">,</span> <span class="n">cov</span> <span class="o">=</span> <span class="n">image_moments</span><span class="p">((</span><span class="n">im</span> <span class="k">for</span> <span class="n">im</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">loader</span><span class="p">),</span>
<span class="g g-Whitespace">     </span><span class="mi">14</span>                         <span class="n">n_batches</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">train_set</span><span class="p">)</span> <span class="o">//</span> <span class="mi">32</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">16</span> <span class="n">pca_encode</span><span class="p">,</span> <span class="n">pca_decode</span> <span class="o">=</span> <span class="n">pca_encoder_decoder</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">cov</span><span class="p">,</span> <span class="n">K</span><span class="p">)</span>

<span class="nn">File ~/opt/anaconda3/envs/nma-course/lib/python3.9/site-packages/torch/utils/data/dataloader.py:633,</span> in <span class="ni">_BaseDataLoaderIter.__next__</span><span class="nt">(self)</span>
<span class="g g-Whitespace">    </span><span class="mi">630</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sampler_iter</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">631</span>     <span class="c1"># TODO(https://github.com/pytorch/pytorch/issues/76750)</span>
<span class="g g-Whitespace">    </span><span class="mi">632</span>     <span class="bp">self</span><span class="o">.</span><span class="n">_reset</span><span class="p">()</span>  <span class="c1"># type: ignore[call-arg]</span>
<span class="ne">--&gt; </span><span class="mi">633</span> <span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_next_data</span><span class="p">()</span>
<span class="g g-Whitespace">    </span><span class="mi">634</span> <span class="bp">self</span><span class="o">.</span><span class="n">_num_yielded</span> <span class="o">+=</span> <span class="mi">1</span>
<span class="g g-Whitespace">    </span><span class="mi">635</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dataset_kind</span> <span class="o">==</span> <span class="n">_DatasetKind</span><span class="o">.</span><span class="n">Iterable</span> <span class="ow">and</span> \
<span class="g g-Whitespace">    </span><span class="mi">636</span>         <span class="bp">self</span><span class="o">.</span><span class="n">_IterableDataset_len_called</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> \
<span class="g g-Whitespace">    </span><span class="mi">637</span>         <span class="bp">self</span><span class="o">.</span><span class="n">_num_yielded</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">_IterableDataset_len_called</span><span class="p">:</span>

<span class="nn">File ~/opt/anaconda3/envs/nma-course/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1328,</span> in <span class="ni">_MultiProcessingDataLoaderIter._next_data</span><span class="nt">(self)</span>
<span class="g g-Whitespace">   </span><span class="mi">1325</span>     <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_process_data</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1327</span> <span class="k">assert</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_shutdown</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tasks_outstanding</span> <span class="o">&gt;</span> <span class="mi">0</span>
<span class="ne">-&gt; </span><span class="mi">1328</span> <span class="n">idx</span><span class="p">,</span> <span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_data</span><span class="p">()</span>
<span class="g g-Whitespace">   </span><span class="mi">1329</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tasks_outstanding</span> <span class="o">-=</span> <span class="mi">1</span>
<span class="g g-Whitespace">   </span><span class="mi">1330</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dataset_kind</span> <span class="o">==</span> <span class="n">_DatasetKind</span><span class="o">.</span><span class="n">Iterable</span><span class="p">:</span>
<span class="g g-Whitespace">   </span><span class="mi">1331</span>     <span class="c1"># Check for _IterableDatasetStopIteration</span>

<span class="nn">File ~/opt/anaconda3/envs/nma-course/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1294,</span> in <span class="ni">_MultiProcessingDataLoaderIter._get_data</span><span class="nt">(self)</span>
<span class="g g-Whitespace">   </span><span class="mi">1290</span>     <span class="c1"># In this case, `self._data_queue` is a `queue.Queue`,. But we don&#39;t</span>
<span class="g g-Whitespace">   </span><span class="mi">1291</span>     <span class="c1"># need to call `.task_done()` because we don&#39;t use `.join()`.</span>
<span class="g g-Whitespace">   </span><span class="mi">1292</span> <span class="k">else</span><span class="p">:</span>
<span class="g g-Whitespace">   </span><span class="mi">1293</span>     <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
<span class="ne">-&gt; </span><span class="mi">1294</span>         <span class="n">success</span><span class="p">,</span> <span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_try_get_data</span><span class="p">()</span>
<span class="g g-Whitespace">   </span><span class="mi">1295</span>         <span class="k">if</span> <span class="n">success</span><span class="p">:</span>
<span class="g g-Whitespace">   </span><span class="mi">1296</span>             <span class="k">return</span> <span class="n">data</span>

<span class="nn">File ~/opt/anaconda3/envs/nma-course/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1145,</span> in <span class="ni">_MultiProcessingDataLoaderIter._try_get_data</span><span class="nt">(self, timeout)</span>
<span class="g g-Whitespace">   </span><span class="mi">1143</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">failed_workers</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
<span class="g g-Whitespace">   </span><span class="mi">1144</span>     <span class="n">pids_str</span> <span class="o">=</span> <span class="s1">&#39;, &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">w</span><span class="o">.</span><span class="n">pid</span><span class="p">)</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">failed_workers</span><span class="p">)</span>
<span class="ne">-&gt; </span><span class="mi">1145</span>     <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s1">&#39;DataLoader worker (pid(s) </span><span class="si">{}</span><span class="s1">) exited unexpectedly&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">pids_str</span><span class="p">))</span> <span class="kn">from</span> <span class="nn">e</span>
<span class="g g-Whitespace">   </span><span class="mi">1146</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">queue</span><span class="o">.</span><span class="n">Empty</span><span class="p">):</span>
<span class="g g-Whitespace">   </span><span class="mi">1147</span>     <span class="k">return</span> <span class="p">(</span><span class="kc">False</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

<span class="ne">RuntimeError</span>: DataLoader worker (pid(s) 76890) exited unexpectedly
</pre></div>
</div>
</div>
</div>
<p>Lets visualize some of the reconstructions (<span class="math notranslate nohighlight">\(\mathbf{x'}\)</span>) side-by-side with the input images (<span class="math notranslate nohighlight">\(\mathbf{x}\)</span>).</p>
<p>Visualize the reconstructions <span class="math notranslate nohighlight">\(\mathbf{x}'\)</span>, run this code a few times to see different examples.</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @markdown Visualize the reconstructions $\mathbf{x}&#39;$, run this code a few times to see different examples.</span>

<span class="n">n_plot</span> <span class="o">=</span> <span class="mi">7</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mf">4.5</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_plot</span><span class="p">):</span>
  <span class="n">idx</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_set</span><span class="p">),</span> <span class="n">size</span><span class="o">=</span><span class="p">())</span>
  <span class="n">image</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">train_set</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
  <span class="c1"># Get reconstructed image from autoencoder</span>
  <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">reconstruction</span> <span class="o">=</span> <span class="n">lin_ae</span><span class="p">(</span><span class="n">image</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">image</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>

  <span class="c1"># Get reconstruction from PCA dimensionality reduction</span>
  <span class="n">h_pca</span> <span class="o">=</span> <span class="n">pca_encode</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
  <span class="n">recon_pca</span> <span class="o">=</span> <span class="n">pca_decode</span><span class="p">(</span><span class="n">h_pca</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">image</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>

  <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">n_plot</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
  <span class="n">plot_torch_image</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Original</span><span class="se">\n</span><span class="s1">Image&#39;</span><span class="p">)</span>

  <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">n_plot</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">n_plot</span><span class="p">)</span>
  <span class="n">plot_torch_image</span><span class="p">(</span><span class="n">reconstruction</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Lin AE</span><span class="se">\n</span><span class="s1">(K=</span><span class="si">{</span><span class="n">K</span><span class="si">}</span><span class="s1">)&#39;</span><span class="p">)</span>

  <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">n_plot</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">+</span> <span class="mi">2</span><span class="o">*</span><span class="n">n_plot</span><span class="p">)</span>
  <span class="n">plot_torch_image</span><span class="p">(</span><span class="n">recon_pca</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;PCA</span><span class="se">\n</span><span class="s1">(K=</span><span class="si">{</span><span class="n">K</span><span class="si">}</span><span class="s1">)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">NameError</span><span class="g g-Whitespace">                                 </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span><span class="p">[</span><span class="mi">37</span><span class="p">],</span> <span class="n">line</span> <span class="mi">10</span>
<span class="g g-Whitespace">      </span><span class="mi">8</span> <span class="c1"># Get reconstructed image from autoencoder</span>
<span class="g g-Whitespace">      </span><span class="mi">9</span> <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
<span class="ne">---&gt; </span><span class="mi">10</span>   <span class="n">reconstruction</span> <span class="o">=</span> <span class="n">lin_ae</span><span class="p">(</span><span class="n">image</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">image</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
<span class="g g-Whitespace">     </span><span class="mi">12</span> <span class="c1"># Get reconstruction from PCA dimensionality reduction</span>
<span class="g g-Whitespace">     </span><span class="mi">13</span> <span class="n">h_pca</span> <span class="o">=</span> <span class="n">pca_encode</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>

<span class="ne">NameError</span>: name &#39;lin_ae&#39; is not defined
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;Figure size 1000x450 with 0 Axes&gt;
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="think-3-1-pca-vs-linear-autoenconder">
<h3>Think! 3.1: PCA vs. Linear autoenconder<a class="headerlink" href="#think-3-1-pca-vs-linear-autoenconder" title="Permalink to this headline"></a></h3>
<p>Compare the PCA-based reconstructions to those from the linear autoencoder. Is one better than the other? Are they equally good? Equally bad?</p>
<p>Try out the above cells with a couple values of K if possible. How does the choice of <span class="math notranslate nohighlight">\(K\)</span> impact reconstruction quality?</p>
<p><a class="reference external" href="https://github.com/NeuromatchAcademy/course-content-dl/tree/main/tutorials/W2D4_GenerativeModels/solutions/W2D4_Tutorial1_Solution_2cc24bef.py"><em>Click for solution</em></a></p>
<div class="section" id="id8">
<h4>Submit your feedback<a class="headerlink" href="#id8" title="Permalink to this headline"></a></h4>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Submit your feedback</span>
<span class="n">content_review</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">feedback_prefix</span><span class="si">}</span><span class="s2">_PCA_vs_LinearAutoEncoder&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "e473d0a1c6f64cf7a7b51c16fde9a670"}
</script></div>
</div>
</div>
</div>
</div>
<div class="section" id="section-3-2-building-a-nonlinear-convolutional-autoencoder">
<h2>Section 3.2: Building a nonlinear convolutional autoencoder<a class="headerlink" href="#section-3-2-building-a-nonlinear-convolutional-autoencoder" title="Permalink to this headline"></a></h2>
<p>Ok so we have linear autoencoders doing about the same thing as PCA. We want to improve on that though! We can do so by adding nonlinearity and convolutions.</p>
<p><strong>Nonlinear:</strong> Wed like to apply autoencoders to learn a more flexible nonlinear mapping between the latent space and the images. Such a mapping can provide a more expressive model that better describes the image data than a linear mapping. This can be achieved by adding nonlinear activation functions to our encoder and decoder!</p>
<p><strong>Convolutional:</strong> As you saw on the day dedicated to RNNs and CNNs, parameter sharing is often a good idea for images! Its quite common to use convolutional layers in autoencoders to share parameters across locations in the image.</p>
<p><strong>Side Note:</strong> The <code class="docutils literal notranslate"><span class="pre">nn.Linear</span></code> layer (used in the linear autoencoder above) has a bias term, which is a learnable offset parameter separate for each output unit. Just like PCA centers the data by subtracting off the mean image (<code class="docutils literal notranslate"><span class="pre">mu</span></code>) before encoding and adds the average back in during decoding, a bias term in the decoder can effectively account for the first moment (mean) of the data (i.e. the average of all images in the training set). Convolution layers do have bias parameters, but the bias is applied per filter rather than per pixel location. If were generating grayscale images (like those in MNIST), then <code class="docutils literal notranslate"><span class="pre">Conv2d</span></code> will learn only one bias across the entire image.</p>
<p>For some conceptual continuity with both PCA and the <code class="docutils literal notranslate"><span class="pre">nn.Linear</span></code> layers above, the next block defines a custom <code class="docutils literal notranslate"><span class="pre">BiasLayer</span></code> for adding a learnable per-pixel offset. This custom layer will be used twice: as the first stage of the encoder and as the final stage of the decoder. Ideally, this means that the rest of the neural net can focus on fitting more interesting fine-grained structure.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">BiasLayer</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">  </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">  Bias Layer</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">shape</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Initialise parameters of bias layer</span>

<span class="sd">    Args:</span>
<span class="sd">      shape: tuple</span>
<span class="sd">        Requisite shape of bias layer</span>

<span class="sd">    Returns:</span>
<span class="sd">      Nothing</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">BiasLayer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="n">init_bias</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">init_bias</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Forward pass</span>

<span class="sd">    Args:</span>
<span class="sd">      x: torch.tensor</span>
<span class="sd">        Input features</span>

<span class="sd">    Returns:</span>
<span class="sd">      Output of bias layer</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">x</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span>
</pre></div>
</div>
</div>
</div>
<p>With that out of the way, we will next define a <strong>nonlinear</strong> and <strong>convolutional</strong> autoencoder. Heres a quick tour of the architecture:</p>
<ol class="simple">
<li><p>The <strong>encoder</strong> once again maps from images to <span class="math notranslate nohighlight">\(\mathbf{h}\in\mathbb{R}^K\)</span>. This will use a <code class="docutils literal notranslate"><span class="pre">BiasLayer</span></code> followed by two convolutional layers (<code class="docutils literal notranslate"><span class="pre">nn.Conv2D</span></code>), followed by flattening and linearly projecting down to <span class="math notranslate nohighlight">\(K\)</span> dimensions. The convolutional layers will have <code class="docutils literal notranslate"><span class="pre">ReLU</span></code> nonlinearities on their outputs.</p></li>
<li><p>The <strong>decoder</strong> inverts this process, taking in vectors of length <span class="math notranslate nohighlight">\(K\)</span> and outputting images. Roughly speaking, its architecture is a mirror image of the encoder: the first decoder layer is linear, followed by two <strong>deconvolution</strong> layers (<a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.ConvTranspose2d.html"><code class="docutils literal notranslate"><span class="pre">ConvTranspose2d</span></code></a>). The <code class="docutils literal notranslate"><span class="pre">ConvTranspose2d</span></code>layers will have <code class="docutils literal notranslate"><span class="pre">ReLU</span></code> nonlinearities on their <em>inputs</em>. This mirror image between the encoder and decoder is a useful and near-ubiquitous convention. The idea is that the decoder can then learn to approximately invert the encoder, but it is not a strict requirement (and it does not guarantee the decoder will be an exact inverse of the encoder!).</p></li>
</ol>
<p>Below is a schematic of the architecture for MNIST. Notice that the width and height dimensions of the image planes reduce after each <code class="docutils literal notranslate"><span class="pre">nn.Conv2d</span></code> and increase after each <code class="docutils literal notranslate"><span class="pre">nn.ConvTranspose2d</span></code>. With CIFAR10, the architecture is the same but the exact sizes will differ.</p>
<img alt="https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl/main/tutorials/W2D4_GenerativeModels/static/conv_sizes.png" src="https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl/main/tutorials/W2D4_GenerativeModels/static/conv_sizes.png" />
<p><a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.ConvTranspose2d.html"><code class="docutils literal notranslate"><span class="pre">torch.nn.ConvTranspose2d</span></code></a> module can be seen as the gradient of <code class="docutils literal notranslate"><span class="pre">Conv2d</span></code> with respect to its input. It is also known as a fractionally-strided convolution or a deconvolution (although it is not an actual deconvolution operation). The following code demonstrates this change in sizes:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dummy_image</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">data_shape</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">in_channels</span> <span class="o">=</span> <span class="n">data_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">out_channels</span> <span class="o">=</span> <span class="mi">7</span>

<span class="n">dummy_conv</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="n">in_channels</span><span class="p">,</span>
                       <span class="n">out_channels</span><span class="o">=</span><span class="n">out_channels</span><span class="p">,</span>
                       <span class="n">kernel_size</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

<span class="n">dummy_deconv</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ConvTranspose2d</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="n">out_channels</span><span class="p">,</span>
                                  <span class="n">out_channels</span><span class="o">=</span><span class="n">in_channels</span><span class="p">,</span>
                                  <span class="n">kernel_size</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Size of image is </span><span class="si">{</span><span class="n">dummy_image</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Size of Conv2D(image) </span><span class="si">{</span><span class="n">dummy_conv</span><span class="p">(</span><span class="n">dummy_image</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Size of ConvTranspose2D(Conv2D(image)) </span><span class="si">{</span><span class="n">dummy_deconv</span><span class="p">(</span><span class="n">dummy_conv</span><span class="p">(</span><span class="n">dummy_image</span><span class="p">))</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Size of image is torch.Size([1, 1, 28, 28])
Size of Conv2D(image) torch.Size([1, 7, 24, 24])
Size of ConvTranspose2D(Conv2D(image)) torch.Size([1, 1, 28, 28])
</pre></div>
</div>
</div>
</div>
<div class="section" id="coding-exercise-3-2-fill-in-code-for-the-convautoencoder-module">
<h3>Coding Exercise 3.2: Fill in code for the <code class="docutils literal notranslate"><span class="pre">ConvAutoEncoder</span></code> module<a class="headerlink" href="#coding-exercise-3-2-fill-in-code-for-the-convautoencoder-module" title="Permalink to this headline"></a></h3>
<p>Complete the <code class="docutils literal notranslate"><span class="pre">ConvAutoEncoder</span></code> class. We use the helper function <code class="docutils literal notranslate"><span class="pre">cout(torch.Tensor,</span> <span class="pre">nn.Conv2D)</span></code> to calculate the output shape of a <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html"><code class="docutils literal notranslate"><span class="pre">nn.Conv2D</span></code></a> layer given a tensor with shape (channels, height, width).</p>
<p>It will use the value for <strong>K</strong> you defined in Coding Exercise 3.1 as we will eventually compare the results of the linear autoencoder that you trained there with this one. To play around with K, change it there and retrain both the linear autoencoder and the convolutional autoencoders.</p>
<p><strong>Do you expect the convolutional autoencoder or the linear autoencoder to reach a lower value of mean squared error (MSE)?</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">ConvAutoEncoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">  </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">  A Convolutional AutoEncoder</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x_dim</span><span class="p">,</span> <span class="n">h_dim</span><span class="p">,</span> <span class="n">n_filters</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">filter_size</span><span class="o">=</span><span class="mi">5</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Initialize parameters of ConvAutoEncoder</span>

<span class="sd">    Args:</span>
<span class="sd">      x_dim: tuple</span>
<span class="sd">        Input dimensions (channels, height, widths)</span>
<span class="sd">      h_dim: int</span>
<span class="sd">        Hidden dimension, bottleneck dimension, K</span>
<span class="sd">      n_filters: int</span>
<span class="sd">        Number of filters (number of output channels)</span>
<span class="sd">      filter_size: int</span>
<span class="sd">        Kernel size</span>

<span class="sd">    Returns:</span>
<span class="sd">      Nothing</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="n">channels</span><span class="p">,</span> <span class="n">height</span><span class="p">,</span> <span class="n">widths</span> <span class="o">=</span> <span class="n">x_dim</span>

    <span class="c1"># Encoder input bias layer</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">enc_bias</span> <span class="o">=</span> <span class="n">BiasLayer</span><span class="p">(</span><span class="n">x_dim</span><span class="p">)</span>

    <span class="c1"># First encoder conv2d layer</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">enc_conv_1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">channels</span><span class="p">,</span> <span class="n">n_filters</span><span class="p">,</span> <span class="n">filter_size</span><span class="p">)</span>

    <span class="c1"># Output shape of the first encoder conv2d layer given x_dim input</span>
    <span class="n">conv_1_shape</span> <span class="o">=</span> <span class="n">cout</span><span class="p">(</span><span class="n">x_dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">enc_conv_1</span><span class="p">)</span>

    <span class="c1"># Second encoder conv2d layer</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">enc_conv_2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">n_filters</span><span class="p">,</span> <span class="n">n_filters</span><span class="p">,</span> <span class="n">filter_size</span><span class="p">)</span>

    <span class="c1"># Output shape of the second encoder conv2d layer given conv_1_shape input</span>
    <span class="n">conv_2_shape</span> <span class="o">=</span> <span class="n">cout</span><span class="p">(</span><span class="n">conv_1_shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">enc_conv_2</span><span class="p">)</span>

    <span class="c1"># The bottleneck is a dense layer, therefore we need a flattenning layer</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">enc_flatten</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">()</span>

    <span class="c1"># Conv output shape is (depth, height, width), so the flatten size is:</span>
    <span class="n">flat_after_conv</span> <span class="o">=</span> <span class="n">conv_2_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">conv_2_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">conv_2_shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>

    <span class="c1"># Encoder Linear layer</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">enc_lin</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">flat_after_conv</span><span class="p">,</span> <span class="n">h_dim</span><span class="p">)</span>

    <span class="c1">####################################################################</span>
    <span class="c1"># Fill in all missing code below (...),</span>
    <span class="c1"># then remove or comment the line below to test your class</span>
    <span class="c1"># Remember that decoder is &quot;undo&quot;-ing what the encoder has done!</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;Please complete the `ConvAutoEncoder` class!&quot;</span><span class="p">)</span>
    <span class="c1">####################################################################</span>
    <span class="c1"># Decoder Linear layer</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dec_lin</span> <span class="o">=</span> <span class="o">...</span>

    <span class="c1"># Unflatten data to (depth, height, width) shape</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dec_unflatten</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Unflatten</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">unflattened_size</span><span class="o">=</span><span class="n">conv_2_shape</span><span class="p">)</span>

    <span class="c1"># First &quot;deconvolution&quot; layer</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dec_deconv_1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ConvTranspose2d</span><span class="p">(</span><span class="n">n_filters</span><span class="p">,</span> <span class="n">n_filters</span><span class="p">,</span> <span class="n">filter_size</span><span class="p">)</span>

    <span class="c1"># Second &quot;deconvolution&quot; layer</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dec_deconv_2</span> <span class="o">=</span> <span class="o">...</span>

    <span class="c1"># Decoder output bias layer</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dec_bias</span> <span class="o">=</span> <span class="n">BiasLayer</span><span class="p">(</span><span class="n">x_dim</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">encode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Encoder</span>

<span class="sd">    Args:</span>
<span class="sd">      x: torch.tensor</span>
<span class="sd">        Input features</span>

<span class="sd">    Returns:</span>
<span class="sd">      h: torch.tensor</span>
<span class="sd">        Encoded output</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">s</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">enc_bias</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">enc_conv_1</span><span class="p">(</span><span class="n">s</span><span class="p">))</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">enc_conv_2</span><span class="p">(</span><span class="n">s</span><span class="p">))</span>
    <span class="n">s</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">enc_flatten</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
    <span class="n">h</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">enc_lin</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">h</span>

  <span class="k">def</span> <span class="nf">decode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">h</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Decoder</span>

<span class="sd">    Args:</span>
<span class="sd">      h: torch.tensor</span>
<span class="sd">        Encoded output</span>

<span class="sd">    Returns:</span>
<span class="sd">      x_prime: torch.tensor</span>
<span class="sd">        Decoded output</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dec_lin</span><span class="p">(</span><span class="n">h</span><span class="p">))</span>
    <span class="n">s</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dec_unflatten</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dec_deconv_1</span><span class="p">(</span><span class="n">s</span><span class="p">))</span>
    <span class="n">s</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dec_deconv_2</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
    <span class="n">x_prime</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dec_bias</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x_prime</span>

  <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Forward pass</span>

<span class="sd">    Args:</span>
<span class="sd">      x: torch.tensor</span>
<span class="sd">        Input features</span>

<span class="sd">    Returns:</span>
<span class="sd">      Decoded output</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>



<span class="n">set_seed</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>
<span class="c1">## Uncomment to test your solution</span>
<span class="c1"># trained_conv_AE = ConvAutoEncoder(data_shape, K)</span>
<span class="c1"># assert trained_conv_AE.encode(train_set[0][0].unsqueeze(0)).numel() == K, &quot;Encoder output size should be K!&quot;</span>
<span class="c1"># conv_losses = train_autoencoder(trained_conv_AE, train_set, device=DEVICE, seed=SEED)</span>
<span class="c1"># plot_conv_ae(lin_losses, conv_losses)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Random seed 2021 has been set.
</pre></div>
</div>
</div>
</div>
<p><a class="reference external" href="https://github.com/NeuromatchAcademy/course-content-dl/tree/main/tutorials/W2D4_GenerativeModels/solutions/W2D4_Tutorial1_Solution_71a661e8.py"><em>Click for solution</em></a></p>
<p>You should see that the <code class="docutils literal notranslate"><span class="pre">ConvAutoEncoder</span></code> achieved lower MSE loss than the linear one. If not, you may need to retrain it (or run another few training epochs from where it left off). We make fewer guarantees on this working with CIFAR10, but it should definitely work with MNIST.</p>
<p>Now lets visually compare the reconstructed images from the linear and nonlinear autoencoders. Keep in mind that both have the same dimensionality for <span class="math notranslate nohighlight">\(\mathbf{h}\)</span>!</p>
<p>Visualize the linear and nonlinear AE outputs</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @markdown Visualize the linear and nonlinear AE outputs</span>
<span class="k">if</span> <span class="n">lin_ae</span><span class="o">.</span><span class="n">enc_lin</span><span class="o">.</span><span class="n">out_features</span> <span class="o">!=</span> <span class="n">trained_conv_AE</span><span class="o">.</span><span class="n">enc_lin</span><span class="o">.</span><span class="n">out_features</span><span class="p">:</span>
   <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;ERROR: your linear and convolutional autoencoders have different values of K&#39;</span><span class="p">)</span>

<span class="n">n_plot</span> <span class="o">=</span> <span class="mi">7</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mf">4.5</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_plot</span><span class="p">):</span>
  <span class="n">idx</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_set</span><span class="p">),</span> <span class="n">size</span><span class="o">=</span><span class="p">())</span>
  <span class="n">image</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">train_set</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
  <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="c1"># Get reconstructed image from linear autoencoder</span>
    <span class="n">lin_recon</span> <span class="o">=</span> <span class="n">lin_ae</span><span class="p">(</span><span class="n">image</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">))[</span><span class="mi">0</span><span class="p">]</span>

    <span class="c1"># Get reconstruction from deep (nonlinear) autoencoder</span>
    <span class="n">nonlin_recon</span> <span class="o">=</span> <span class="n">trained_conv_AE</span><span class="p">(</span><span class="n">image</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">))[</span><span class="mi">0</span><span class="p">]</span>

  <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">n_plot</span><span class="p">,</span> <span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
  <span class="n">plot_torch_image</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Original</span><span class="se">\n</span><span class="s1">Image&#39;</span><span class="p">)</span>

  <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">n_plot</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">n_plot</span><span class="p">)</span>
  <span class="n">plot_torch_image</span><span class="p">(</span><span class="n">lin_recon</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Lin AE</span><span class="se">\n</span><span class="s1">(K=</span><span class="si">{</span><span class="n">K</span><span class="si">}</span><span class="s1">)&#39;</span><span class="p">)</span>

  <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">n_plot</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">+</span> <span class="mi">2</span><span class="o">*</span><span class="n">n_plot</span><span class="p">)</span>
  <span class="n">plot_torch_image</span><span class="p">(</span><span class="n">nonlin_recon</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;NonLin AE</span><span class="se">\n</span><span class="s1">(K=</span><span class="si">{</span><span class="n">K</span><span class="si">}</span><span class="s1">)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">NameError</span><span class="g g-Whitespace">                                 </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span><span class="p">[</span><span class="mi">42</span><span class="p">],</span> <span class="n">line</span> <span class="mi">2</span>
<span class="g g-Whitespace">      </span><span class="mi">1</span> <span class="c1"># @markdown Visualize the linear and nonlinear AE outputs</span>
<span class="ne">----&gt; </span><span class="mi">2</span> <span class="k">if</span> <span class="n">lin_ae</span><span class="o">.</span><span class="n">enc_lin</span><span class="o">.</span><span class="n">out_features</span> <span class="o">!=</span> <span class="n">trained_conv_AE</span><span class="o">.</span><span class="n">enc_lin</span><span class="o">.</span><span class="n">out_features</span><span class="p">:</span>
<span class="g g-Whitespace">      </span><span class="mi">3</span>    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;ERROR: your linear and convolutional autoencoders have different values of K&#39;</span><span class="p">)</span>
<span class="g g-Whitespace">      </span><span class="mi">5</span> <span class="n">n_plot</span> <span class="o">=</span> <span class="mi">7</span>

<span class="ne">NameError</span>: name &#39;lin_ae&#39; is not defined
</pre></div>
</div>
</div>
</div>
<div class="section" id="id9">
<h4>Submit your feedback<a class="headerlink" href="#id9" title="Permalink to this headline"></a></h4>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Submit your feedback</span>
<span class="n">content_review</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">feedback_prefix</span><span class="si">}</span><span class="s2">_NonLinear_AutoEncoder_Exercise&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "e5ce04eb206a448184106fd4a83c663d"}
</script></div>
</div>
</div>
</div>
</div>
</div>
<hr class="docutils" />
<div class="section" id="section-4-variational-auto-encoders-vaes">
<h1>Section 4: Variational Auto-Encoders (VAEs)<a class="headerlink" href="#section-4-variational-auto-encoders-vaes" title="Permalink to this headline"></a></h1>
<p><em>Time estimate: ~25mins</em></p>
<p><strong>Please</strong> run the cell after the video to train a VAE for MNIST while watching it.</p>
<div class="section" id="video-4-variational-autoencoders">
<h2>Video 4: Variational Autoencoders<a class="headerlink" href="#video-4-variational-autoencoders" title="Permalink to this headline"></a></h2>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "7e1a6bf830aa4c358f2de5a96df492d5"}
</script></div>
</div>
</div>
<div class="section" id="id10">
<h2>Submit your feedback<a class="headerlink" href="#id10" title="Permalink to this headline"></a></h2>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Submit your feedback</span>
<span class="n">content_review</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">feedback_prefix</span><span class="si">}</span><span class="s2">_Variational_AutoEncoder_Video&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "9eeabf23a07240b2874d18c226027867"}
</script></div>
</div>
<p>Train a VAE for MNIST while watching the video. (Note: this VAE has a 2D latent space. If you are feeling ambitious, edit the code and modify the latent space dimensionality and see what happens.)</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @markdown Train a VAE for MNIST while watching the video. (Note: this VAE has a 2D latent space. If you are feeling ambitious, edit the code and modify the latent space dimensionality and see what happens.)</span>
<span class="n">K_VAE</span> <span class="o">=</span> <span class="mi">2</span>


<span class="k">class</span> <span class="nc">ConvVAE</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">  </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">  Convolutional Variational Autoencoder</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">K</span><span class="p">,</span> <span class="n">num_filters</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">filter_size</span><span class="o">=</span><span class="mi">5</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Initialize parameters of ConvVAE</span>

<span class="sd">    Args:</span>
<span class="sd">      K: int</span>
<span class="sd">        Bottleneck dimensionality</span>
<span class="sd">      num_filters: int</span>
<span class="sd">        Number of filters [default: 32]</span>
<span class="sd">      filter_size: int</span>
<span class="sd">        Filter size [default: 5]</span>

<span class="sd">    Returns:</span>
<span class="sd">      Nothing</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nb">super</span><span class="p">(</span><span class="n">ConvVAE</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="c1"># With padding=0, the number of pixels cut off from</span>
    <span class="c1"># each image dimension</span>
    <span class="c1"># is filter_size // 2. Double it to get the amount</span>
    <span class="c1"># of pixels lost in</span>
    <span class="c1"># width and height per Conv2D layer, or added back</span>
    <span class="c1"># in per</span>
    <span class="c1"># ConvTranspose2D layer.</span>
    <span class="n">filter_reduction</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">filter_size</span> <span class="o">//</span> <span class="mi">2</span><span class="p">)</span>

    <span class="c1"># After passing input through two Conv2d layers,</span>
    <span class="c1"># the shape will be</span>
    <span class="c1"># &#39;shape_after_conv&#39;. This is also the shape that</span>
    <span class="c1"># will go into the first</span>
    <span class="c1"># deconvolution layer in the decoder</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">shape_after_conv</span> <span class="o">=</span> <span class="p">(</span><span class="n">num_filters</span><span class="p">,</span>
                              <span class="n">data_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">-</span><span class="mi">2</span><span class="o">*</span><span class="n">filter_reduction</span><span class="p">,</span>
                              <span class="n">data_shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">-</span><span class="mi">2</span><span class="o">*</span><span class="n">filter_reduction</span><span class="p">)</span>
    <span class="n">flat_size_after_conv</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">shape_after_conv</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> \
        <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">shape_after_conv</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> \
        <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">shape_after_conv</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>

    <span class="c1"># Define the recognition model (encoder or q) part</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">q_bias</span> <span class="o">=</span> <span class="n">BiasLayer</span><span class="p">(</span><span class="n">data_shape</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">q_conv_1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">data_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">num_filters</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">q_conv_2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">num_filters</span><span class="p">,</span> <span class="n">num_filters</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">q_flatten</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">q_fc_phi</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">flat_size_after_conv</span><span class="p">,</span> <span class="n">K</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># Define the generative model (decoder or p) part</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">p_fc_upsample</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">K</span><span class="p">,</span> <span class="n">flat_size_after_conv</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">p_unflatten</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Unflatten</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">shape_after_conv</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">p_deconv_1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ConvTranspose2d</span><span class="p">(</span><span class="n">num_filters</span><span class="p">,</span> <span class="n">num_filters</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">p_deconv_2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ConvTranspose2d</span><span class="p">(</span><span class="n">num_filters</span><span class="p">,</span> <span class="n">data_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">5</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">p_bias</span> <span class="o">=</span> <span class="n">BiasLayer</span><span class="p">(</span><span class="n">data_shape</span><span class="p">)</span>

    <span class="c1"># Define a special extra parameter to learn</span>
    <span class="c1"># scalar sig_x for all pixels</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">log_sig_x</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(()))</span>

  <span class="k">def</span> <span class="nf">infer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Map (batch of) x to (batch of) phi which</span>
<span class="sd">    can then be passed to</span>
<span class="sd">    rsample to get z</span>

<span class="sd">    Args:</span>
<span class="sd">      x: torch.tensor</span>
<span class="sd">        Input features</span>

<span class="sd">    Returns:</span>
<span class="sd">      phi: np.ndarray</span>
<span class="sd">        Relative entropy</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">s</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q_bias</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">q_conv_1</span><span class="p">(</span><span class="n">s</span><span class="p">))</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">q_conv_2</span><span class="p">(</span><span class="n">s</span><span class="p">))</span>
    <span class="n">flat_s</span> <span class="o">=</span> <span class="n">s</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">s</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">phi</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q_fc_phi</span><span class="p">(</span><span class="n">flat_s</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">phi</span>

  <span class="k">def</span> <span class="nf">generate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">zs</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Map [b,n,k] sized samples of z to</span>
<span class="sd">    [b,n,p] sized images</span>

<span class="sd">    Args:</span>
<span class="sd">      zs: np.ndarray</span>
<span class="sd">        Samples</span>

<span class="sd">    Returns:</span>
<span class="sd">      mu_zs: np.ndarray</span>
<span class="sd">        Mean of samples</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Note that for the purposes of passing</span>
    <span class="c1"># through the generator, we need</span>
    <span class="c1"># to reshape zs to be size [b*n,k]</span>
    <span class="n">b</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">k</span> <span class="o">=</span> <span class="n">zs</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">zs</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">b</span><span class="o">*</span><span class="n">n</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">p_fc_upsample</span><span class="p">(</span><span class="n">s</span><span class="p">))</span><span class="o">.</span><span class="n">view</span><span class="p">((</span><span class="n">b</span><span class="o">*</span><span class="n">n</span><span class="p">,)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">shape_after_conv</span><span class="p">)</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">p_deconv_1</span><span class="p">(</span><span class="n">s</span><span class="p">))</span>
    <span class="n">s</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">p_deconv_2</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
    <span class="n">s</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">p_bias</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
    <span class="n">mu_xs</span> <span class="o">=</span> <span class="n">s</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">mu_xs</span>

  <span class="k">def</span> <span class="nf">decode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">zs</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Decoder</span>

<span class="sd">    Args:</span>
<span class="sd">      zs: np.ndarray</span>
<span class="sd">        Samples</span>

<span class="sd">    Returns:</span>
<span class="sd">      Generated images</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Included for compatability with conv-AE code</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">zs</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>

  <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Forward pass</span>

<span class="sd">    Args:</span>
<span class="sd">      x: torch.tensor</span>
<span class="sd">        Input image</span>

<span class="sd">    Returns:</span>
<span class="sd">      Generated images</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># VAE.forward() is not used for training,</span>
    <span class="c1"># but we&#39;ll treat it like a</span>
    <span class="c1"># classic autoencoder by taking a single</span>
    <span class="c1"># sample of z ~ q</span>
    <span class="n">phi</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">infer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">zs</span> <span class="o">=</span> <span class="n">rsample</span><span class="p">(</span><span class="n">phi</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">zs</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>

  <span class="k">def</span> <span class="nf">elbo</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Run input end to end through the VAE</span>
<span class="sd">    and compute the ELBO using n</span>
<span class="sd">    samples of z</span>

<span class="sd">    Args:</span>
<span class="sd">      x: torch.tensor</span>
<span class="sd">        Input image</span>
<span class="sd">      n: int</span>
<span class="sd">        Number of samples of z</span>

<span class="sd">    Returns:</span>
<span class="sd">      Difference between true and estimated KL divergence</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">phi</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">infer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">zs</span> <span class="o">=</span> <span class="n">rsample</span><span class="p">(</span><span class="n">phi</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
    <span class="n">mu_xs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">zs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">log_p_x</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">mu_xs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_sig_x</span><span class="o">.</span><span class="n">exp</span><span class="p">())</span> <span class="o">-</span> <span class="n">kl_q_p</span><span class="p">(</span><span class="n">zs</span><span class="p">,</span> <span class="n">phi</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">expected_z</span><span class="p">(</span><span class="n">phi</span><span class="p">):</span>
<span class="w">  </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">  Expected sample entropy</span>

<span class="sd">  Args:</span>
<span class="sd">    phi: list</span>
<span class="sd">      Relative entropy</span>

<span class="sd">  Returns:</span>
<span class="sd">    Expected sample entropy</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">return</span> <span class="n">phi</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>


<span class="k">def</span> <span class="nf">rsample</span><span class="p">(</span><span class="n">phi</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">):</span>
<span class="w">  </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">  Sample z ~ q(z;phi)</span>
<span class="sd">  Output z is size [b,n_samples,K] given</span>
<span class="sd">  phi with shape [b,K+1]. The first K</span>
<span class="sd">  entries of each row of phi are the mean of q,</span>
<span class="sd">  and phi[:,-1] is the log</span>
<span class="sd">  standard deviation</span>

<span class="sd">  Args:</span>
<span class="sd">    phi: list</span>
<span class="sd">      Relative entropy</span>
<span class="sd">    n_samples: int</span>
<span class="sd">      Number of samples</span>

<span class="sd">  Returns:</span>
<span class="sd">    Output z is size [b,n_samples,K] given</span>
<span class="sd">  phi with shape [b,K+1]. The first K</span>
<span class="sd">  entries of each row of phi are the mean of q,</span>
<span class="sd">  and phi[:,-1] is the log</span>
<span class="sd">  standard deviation</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">b</span><span class="p">,</span> <span class="n">kplus1</span> <span class="o">=</span> <span class="n">phi</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
  <span class="n">k</span> <span class="o">=</span> <span class="n">kplus1</span><span class="o">-</span><span class="mi">1</span>
  <span class="n">mu</span><span class="p">,</span> <span class="n">sig</span> <span class="o">=</span> <span class="n">phi</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">phi</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">exp</span><span class="p">()</span>
  <span class="n">eps</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">phi</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">eps</span><span class="o">*</span><span class="n">sig</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">b</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="n">mu</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">b</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="n">k</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">train_vae</span><span class="p">(</span><span class="n">vae</span><span class="p">,</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">n_samples</span><span class="o">=</span><span class="mi">1000</span><span class="p">):</span>
<span class="w">  </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">  Train VAE</span>

<span class="sd">  Args:</span>
<span class="sd">    vae: nn.module</span>
<span class="sd">      Model</span>
<span class="sd">    dataset: function</span>
<span class="sd">      Dataset</span>
<span class="sd">    epochs: int</span>
<span class="sd">      Epochs</span>
<span class="sd">    n_samples: int</span>
<span class="sd">      Number of samples</span>

<span class="sd">  Returns:</span>
<span class="sd">    elbo_vals: list</span>
<span class="sd">      List of values obtained from ELBO</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">opt</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">vae</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span> <span class="n">weight_decay</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
  <span class="n">elbo_vals</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="n">vae</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
  <span class="n">vae</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
  <span class="n">loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">250</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">pin_memory</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
  <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="n">trange</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="s1">&#39;Epochs&#39;</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">im</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">loader</span><span class="p">,</span> <span class="n">total</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span> <span class="o">//</span> <span class="mi">250</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="s1">&#39;Batches&#39;</span><span class="p">,</span> <span class="n">leave</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
      <span class="n">im</span> <span class="o">=</span> <span class="n">im</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
      <span class="n">opt</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
      <span class="n">loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">vae</span><span class="o">.</span><span class="n">elbo</span><span class="p">(</span><span class="n">im</span><span class="p">)</span>
      <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
      <span class="n">opt</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

      <span class="n">elbo_vals</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="o">-</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
  <span class="n">vae</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span>
  <span class="n">vae</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
  <span class="k">return</span> <span class="n">elbo_vals</span>


<span class="n">trained_conv_VarAE</span> <span class="o">=</span> <span class="n">ConvVAE</span><span class="p">(</span><span class="n">K</span><span class="o">=</span><span class="n">K_VAE</span><span class="p">)</span>
<span class="n">elbo_vals</span> <span class="o">=</span> <span class="n">train_vae</span><span class="p">(</span><span class="n">trained_conv_VarAE</span><span class="p">,</span> <span class="n">train_set</span><span class="p">,</span> <span class="n">n_samples</span><span class="o">=</span><span class="mi">10000</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Learned sigma_x is </span><span class="si">{</span><span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">trained_conv_VarAE</span><span class="o">.</span><span class="n">log_sig_x</span><span class="p">)</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="c1"># Uncomment below if you&#39;d like to see the the training</span>
<span class="c1"># curve of the evaluated ELBO loss function</span>
<span class="c1"># ELBO is the loss function used to train VAEs</span>
<span class="c1"># (see lecture!)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">elbo_vals</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Batch #&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;ELBO&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "f1eadb29c15448488462a4a84e7fdeb4"}
</script><script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "855a7164eaf043449321da20664ace34"}
</script><script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "2f9b070a9caf4fb5b91c4f8ce9ef4701"}
</script><script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "1ed93aa037bb420788f37236312eaec8"}
</script><script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "376cf654a23a4ea19aa909fffb83faa7"}
</script><script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "32d5e9cbba7c49d8af523de0402e44a0"}
</script><script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "8d1d992710a9407bae98f0b6303cbbf9"}
</script><script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "2ca8d19777154da2b375d219d2566087"}
</script><script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "eabea8b88e8d437dbf5b1681352b23d5"}
</script><script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "f08012c0108747318f480fa984aaf05c"}
</script><div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">KeyboardInterrupt</span><span class="g g-Whitespace">                         </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span><span class="p">[</span><span class="mi">46</span><span class="p">],</span> <span class="n">line</span> <span class="mi">247</span>
<span class="g g-Whitespace">    </span><span class="mi">243</span>   <span class="k">return</span> <span class="n">elbo_vals</span>
<span class="g g-Whitespace">    </span><span class="mi">246</span> <span class="n">trained_conv_VarAE</span> <span class="o">=</span> <span class="n">ConvVAE</span><span class="p">(</span><span class="n">K</span><span class="o">=</span><span class="n">K_VAE</span><span class="p">)</span>
<span class="ne">--&gt; </span><span class="mi">247</span> <span class="n">elbo_vals</span> <span class="o">=</span> <span class="n">train_vae</span><span class="p">(</span><span class="n">trained_conv_VarAE</span><span class="p">,</span> <span class="n">train_set</span><span class="p">,</span> <span class="n">n_samples</span><span class="o">=</span><span class="mi">10000</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">249</span> <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Learned sigma_x is </span><span class="si">{</span><span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">trained_conv_VarAE</span><span class="o">.</span><span class="n">log_sig_x</span><span class="p">)</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">251</span> <span class="c1"># Uncomment below if you&#39;d like to see the the training</span>
<span class="g g-Whitespace">    </span><span class="mi">252</span> <span class="c1"># curve of the evaluated ELBO loss function</span>
<span class="g g-Whitespace">    </span><span class="mi">253</span> <span class="c1"># ELBO is the loss function used to train VAEs</span>
<span class="g g-Whitespace">    </span><span class="mi">254</span> <span class="c1"># (see lecture!)</span>

<span class="nn">Cell In[46], line 237,</span> in <span class="ni">train_vae</span><span class="nt">(vae, dataset, epochs, n_samples)</span>
<span class="g g-Whitespace">    </span><span class="mi">235</span> <span class="n">opt</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
<span class="g g-Whitespace">    </span><span class="mi">236</span> <span class="n">loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">vae</span><span class="o">.</span><span class="n">elbo</span><span class="p">(</span><span class="n">im</span><span class="p">)</span>
<span class="ne">--&gt; </span><span class="mi">237</span> <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
<span class="g g-Whitespace">    </span><span class="mi">238</span> <span class="n">opt</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
<span class="g g-Whitespace">    </span><span class="mi">240</span> <span class="n">elbo_vals</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="o">-</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>

<span class="nn">File ~/opt/anaconda3/envs/nma-course/lib/python3.9/site-packages/torch/_tensor.py:487,</span> in <span class="ni">Tensor.backward</span><span class="nt">(self, gradient, retain_graph, create_graph, inputs)</span>
<span class="g g-Whitespace">    </span><span class="mi">477</span> <span class="k">if</span> <span class="n">has_torch_function_unary</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="g g-Whitespace">    </span><span class="mi">478</span>     <span class="k">return</span> <span class="n">handle_torch_function</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">479</span>         <span class="n">Tensor</span><span class="o">.</span><span class="n">backward</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">480</span>         <span class="p">(</span><span class="bp">self</span><span class="p">,),</span>
   <span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">485</span>         <span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">486</span>     <span class="p">)</span>
<span class="ne">--&gt; </span><span class="mi">487</span> <span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">488</span>     <span class="bp">self</span><span class="p">,</span> <span class="n">gradient</span><span class="p">,</span> <span class="n">retain_graph</span><span class="p">,</span> <span class="n">create_graph</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span>
<span class="g g-Whitespace">    </span><span class="mi">489</span> <span class="p">)</span>

<span class="nn">File ~/opt/anaconda3/envs/nma-course/lib/python3.9/site-packages/torch/autograd/__init__.py:200,</span> in <span class="ni">backward</span><span class="nt">(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)</span>
<span class="g g-Whitespace">    </span><span class="mi">195</span>     <span class="n">retain_graph</span> <span class="o">=</span> <span class="n">create_graph</span>
<span class="g g-Whitespace">    </span><span class="mi">197</span> <span class="c1"># The reason we repeat same the comment below is that</span>
<span class="g g-Whitespace">    </span><span class="mi">198</span> <span class="c1"># some Python versions print out the first line of a multi-line function</span>
<span class="g g-Whitespace">    </span><span class="mi">199</span> <span class="c1"># calls in the traceback and some print out the last line</span>
<span class="ne">--&gt; </span><span class="mi">200</span> <span class="n">Variable</span><span class="o">.</span><span class="n">_execution_engine</span><span class="o">.</span><span class="n">run_backward</span><span class="p">(</span>  <span class="c1"># Calls into the C++ engine to run the backward pass</span>
<span class="g g-Whitespace">    </span><span class="mi">201</span>     <span class="n">tensors</span><span class="p">,</span> <span class="n">grad_tensors_</span><span class="p">,</span> <span class="n">retain_graph</span><span class="p">,</span> <span class="n">create_graph</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">202</span>     <span class="n">allow_unreachable</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">accumulate_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="ne">KeyboardInterrupt</span>: 
</pre></div>
</div>
</div>
</div>
<p>ELBO is the loss function used to train VAEs - note that we are maximizing ELBO (higher ELBO is better). We implement this in PyTorch code set up to minimize things by making the loss equal to negative ELBO.</p>
</div>
<div class="section" id="section-4-1-components-of-a-vae">
<h2>Section 4.1: Components of a VAE<a class="headerlink" href="#section-4-1-components-of-a-vae" title="Permalink to this headline"></a></h2>
<p><em>Recognition models and density networks</em></p>
<p>Variational AutoEncoders (VAEs) are a lot like the classic AutoEncoders (AEs), but where we explicitly think about probability distributions. In the language of VAEs, the <strong>encoder</strong> is replaced with a <strong>recognition model</strong>, and the <strong>decoder</strong> is replaced with a <strong>density network</strong>.</p>
<p>Where in a classic autoencoder the encoder maps from images to a single hidden vector,</p>
<div class="amsmath math notranslate nohighlight" id="equation-db847912-0209-427e-b0be-d477acd2c6a9">
<span class="eqno">(89)<a class="headerlink" href="#equation-db847912-0209-427e-b0be-d477acd2c6a9" title="Permalink to this equation"></a></span>\[\begin{equation}
\mathbf{x} \overset{\text{AE}}{\longrightarrow} \mathbf{h} \, ,
\end{equation}\]</div>
<p>in a VAE we would say that a recognition model maps from inputs to entire <strong>distributions</strong> over hidden vectors,</p>
<div class="amsmath math notranslate nohighlight" id="equation-6c18de28-0d3f-4aa2-aea3-83d64c869477">
<span class="eqno">(90)<a class="headerlink" href="#equation-6c18de28-0d3f-4aa2-aea3-83d64c869477" title="Permalink to this equation"></a></span>\[\begin{equation}
\mathbf{x} \overset{\text{VAE}}{\longrightarrow} q_{\mathbf{w_e}}(\mathbf{z}) \, ,
\end{equation}\]</div>
<p>which we will then sample from. Here <span class="math notranslate nohighlight">\(\mathbf{w_e}\)</span> refers to the weights of the recognition model, which parametarize our distribution generating network. Well say more in a moment about what kind of distribution <span class="math notranslate nohighlight">\(q_{\mathbf{w_e}}(\mathbf{z})\)</span> is.
Part of what makes VAEs work is that the loss function will require good reconstructions of the input not just for a single <span class="math notranslate nohighlight">\(\mathbf{z}\)</span>, but <em>on average</em> from samples of <span class="math notranslate nohighlight">\(\mathbf{z} \sim q_{\mathbf{w_e}}(\mathbf{z})\)</span>.</p>
<p>In the classic autoencoder, we had a decoder which maps from hidden vectors to reconstructions of the input:</p>
<div class="amsmath math notranslate nohighlight" id="equation-5c4501e3-e71e-400d-9e24-6878b1b1900e">
<span class="eqno">(91)<a class="headerlink" href="#equation-5c4501e3-e71e-400d-9e24-6878b1b1900e" title="Permalink to this equation"></a></span>\[\begin{equation}
\mathbf{h} \overset{\text{AE}}{\longrightarrow} \mathbf{x'} \, .
\end{equation}\]</div>
<p>In a density network, reconstructions are expressed in terms of a distribution:</p>
<div class="amsmath math notranslate nohighlight" id="equation-8cafdab5-6dff-4135-80be-42c94b3e518c">
<span class="eqno">(92)<a class="headerlink" href="#equation-8cafdab5-6dff-4135-80be-42c94b3e518c" title="Permalink to this equation"></a></span>\[\begin{equation}
\mathbf{z} \overset{\text{VAE}}{\longrightarrow} p_{\mathbf{w_d}}(\mathbf{x}|\mathbf{z})
\end{equation}\]</div>
<p>where, as above, <span class="math notranslate nohighlight">\(p_{\mathbf{w_d}}(\mathbf{x}|\mathbf{z})\)</span> is defined by mapping <span class="math notranslate nohighlight">\(\mathbf{z}\)</span> through a density network then treating the resulting <span class="math notranslate nohighlight">\(f(\mathbf{z};\mathbf{w_d})\)</span> as the mean of a (Gaussian) distribution over <span class="math notranslate nohighlight">\(\mathbf{x}\)</span>. Similarly, our reconstruction distribution is parametarized by the weights of the density network.</p>
</div>
<div class="section" id="section-4-2-generating-novel-images-from-the-decoder">
<h2>Section 4.2: Generating novel images from the decoder<a class="headerlink" href="#section-4-2-generating-novel-images-from-the-decoder" title="Permalink to this headline"></a></h2>
<p>If we isolate the decoder part of the AutoEncoder, what we have is a neural network that takes as input a vector of size <span class="math notranslate nohighlight">\(K\)</span> and produces as output an image that looks something like our training data. Recall that in our earlier notation, we had an input <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> that was mapped to a low-dimensional hidden representation <span class="math notranslate nohighlight">\(\mathbf{h}\)</span> which was then decoded into a reconstruction of the input, <span class="math notranslate nohighlight">\(\mathbf{x'}\)</span>:</p>
<div class="amsmath math notranslate nohighlight" id="equation-f30a4b4e-3819-49c2-941a-e91a58b5b1cf">
<span class="eqno">(93)<a class="headerlink" href="#equation-f30a4b4e-3819-49c2-941a-e91a58b5b1cf" title="Permalink to this equation"></a></span>\[\begin{equation}
\mathbf{x} \overset{\text{encode}}{\longrightarrow} \mathbf{h} \overset{\text{decode}}{\longrightarrow} \mathbf{x'}\, .
\end{equation}\]</div>
<p>Partly as a matter of convention, and partly to distinguish where we are going next from the previous section, were going to introduce a new variable, <span class="math notranslate nohighlight">\(\mathbf{z} \in \mathbb{R}^K\)</span>, which will take the place of <span class="math notranslate nohighlight">\(\mathbf{h}\)</span>. The key difference is that while <span class="math notranslate nohighlight">\(\mathbf{h}\)</span> is produced by the encoder for a particular <span class="math notranslate nohighlight">\(\mathbf{x}\)</span>, <span class="math notranslate nohighlight">\(\mathbf{z}\)</span> will be drawn out of thin air from a prior of our choosing:</p>
<div class="amsmath math notranslate nohighlight" id="equation-c92a1226-2367-4498-8e8d-fbf6e652a40c">
<span class="eqno">(94)<a class="headerlink" href="#equation-c92a1226-2367-4498-8e8d-fbf6e652a40c" title="Permalink to this equation"></a></span>\[\begin{equation}
\mathbf{z} \sim p(\mathbf{z})\\ \mathbf{z} \overset{\text{decode}}{\longrightarrow} \mathbf{x}\, .
\end{equation}\]</div>
<p>(Note that it is also common convention to drop the prime on <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> when it is no longer being thought of as a reconstruction).</p>
<div class="section" id="coding-exercise-4-2-generating-images">
<h3>Coding Exercise 4.2: Generating images<a class="headerlink" href="#coding-exercise-4-2-generating-images" title="Permalink to this headline"></a></h3>
<p>Complete the code below to generate some images from the VAE that we trained above.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">generate_images</span><span class="p">(</span><span class="n">autoencoder</span><span class="p">,</span> <span class="n">K</span><span class="p">,</span> <span class="n">n_images</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
<span class="w">  </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">  Generate n_images &#39;new&#39; images from the decoder part of the given</span>
<span class="sd">  autoencoder.</span>

<span class="sd">  Args:</span>
<span class="sd">    autoencoder: nn.module</span>
<span class="sd">      Autoencoder model</span>
<span class="sd">    K: int</span>
<span class="sd">      Bottleneck dimension</span>
<span class="sd">    n_images: int</span>
<span class="sd">      Number of images</span>

<span class="sd">  Returns:</span>
<span class="sd">    x: torch.tensor</span>
<span class="sd">      (n_images, channels, height, width) tensor of images</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="c1"># Concatenate tuples to get (n_images, channels, height, width)</span>
  <span class="n">output_shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">n_images</span><span class="p">,)</span> <span class="o">+</span> <span class="n">data_shape</span>
  <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="c1">####################################################################</span>
    <span class="c1"># Fill in all missing code below (...),</span>
    <span class="c1"># then remove or comment the line below to test your function</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;Please complete the `generate_images` function!&quot;</span><span class="p">)</span>
    <span class="c1">####################################################################</span>
    <span class="c1"># Sample z from a unit gaussian, pass through autoencoder.decode()</span>
    <span class="n">z</span> <span class="o">=</span> <span class="o">...</span>
    <span class="n">x</span> <span class="o">=</span> <span class="o">...</span>

    <span class="k">return</span> <span class="n">x</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">output_shape</span><span class="p">)</span>



<span class="n">set_seed</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>
<span class="c1">## Uncomment to test your solution</span>
<span class="c1"># images = generate_images(trained_conv_AE, K, n_images=9)</span>
<span class="c1"># plot_images(images, plt_title=&#39;Images Generated from the Conv-AE&#39;)</span>
<span class="c1"># images = generate_images(trained_conv_VarAE, K_VAE, n_images=9)</span>
<span class="c1"># plot_images(images, plt_title=&#39;Images Generated from a Conv-Variational-AE&#39;)</span>
</pre></div>
</div>
</div>
</div>
<p><a class="reference external" href="https://github.com/NeuromatchAcademy/course-content-dl/tree/main/tutorials/W2D4_GenerativeModels/solutions/W2D4_Tutorial1_Solution_775a81ae.py"><em>Click for solution</em></a></p>
<div class="section" id="id11">
<h4>Submit your feedback<a class="headerlink" href="#id11" title="Permalink to this headline"></a></h4>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Submit your feedback</span>
<span class="n">content_review</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">feedback_prefix</span><span class="si">}</span><span class="s2">_Generating_images_Exercise&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="think-4-2-autoencoders-vs-variational-autoencoders">
<h3>Think! 4.2: AutoEncoders vs. Variational AutoEncoders<a class="headerlink" href="#think-4-2-autoencoders-vs-variational-autoencoders" title="Permalink to this headline"></a></h3>
<p>Compare the images generated by the AutoEncoder to the images generated by the Variational AutoEncoder. You can run the code a few times to see a variety of examples.</p>
<p>Does one set look more like the training set (handwritten digits) than the other? What is driving this difference?</p>
<p><a class="reference external" href="https://github.com/NeuromatchAcademy/course-content-dl/tree/main/tutorials/W2D4_GenerativeModels/solutions/W2D4_Tutorial1_Solution_0e74baf7.py"><em>Click for solution</em></a></p>
<div class="section" id="id12">
<h4>Submit your feedback<a class="headerlink" href="#id12" title="Permalink to this headline"></a></h4>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Submit your feedback</span>
<span class="n">content_review</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">feedback_prefix</span><span class="si">}</span><span class="s2">_AutoEncoders_vs_Variational_AutoEncoders_Discussion&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<hr class="docutils" />
<div class="section" id="section-5-state-of-the-art-vaes-and-wrap-up">
<h1>Section 5: State of the art VAEs and Wrap-up<a class="headerlink" href="#section-5-state-of-the-art-vaes-and-wrap-up" title="Permalink to this headline"></a></h1>
<div class="section" id="video-5-state-of-the-art-vaes">
<h2>Video 5: State-Of-The-Art VAEs<a class="headerlink" href="#video-5-state-of-the-art-vaes" title="Permalink to this headline"></a></h2>
<div class="cell tag_remove-input docutils container">
</div>
</div>
<div class="section" id="id13">
<h2>Submit your feedback<a class="headerlink" href="#id13" title="Permalink to this headline"></a></h2>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Submit your feedback</span>
<span class="n">content_review</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">feedback_prefix</span><span class="si">}</span><span class="s2">_SOTA_VAEs_and_WrapUp_Video&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<hr class="docutils" />
<div class="section" id="summary">
<h1>Summary<a class="headerlink" href="#summary" title="Permalink to this headline"></a></h1>
<p>Through this tutorial, we have learned</p>
<ul class="simple">
<li><p>What a generative model is and why we are interested in them.</p></li>
<li><p>How latent variable models relate to generative models with the example of pPCA.</p></li>
<li><p>What a basic AutoEncoder is and how they relate to other latent variable models.</p></li>
<li><p>The basics of Variational AutoEncoders and how they function as generative models.</p></li>
<li><p>An introduction to the broad applications of VAEs.</p></li>
</ul>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./tutorials/W2D4_GenerativeModels/student"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="../chapter_title.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Generative Models</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="W2D4_Tutorial2.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Tutorial 2: Diffusion models</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Neuromatch<br/>
  
    <div class="extra_footer">
      <div>
<a href="http://creativecommons.org/licenses/by/4.0/"><img src="https://i.creativecommons.org/l/by/4.0/88x31.png"></a>
<a href="https://opensource.org/licenses/BSD-3-Clause"><img src="https://camo.githubusercontent.com/9b9ea65d95c9ef878afa1987df65731d47681336/68747470733a2f2f696d672e736869656c64732e696f2f707970692f6c2f736561626f726e2e737667"></a>
The contents of this repository are shared under under a <a href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a>.
Software elements are additionally licensed under the <a href="https://opensource.org/licenses/BSD-3-Clause">BSD (3-Clause) License</a>.
</div>

    </div>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>